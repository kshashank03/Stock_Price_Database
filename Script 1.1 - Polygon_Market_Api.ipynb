{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "# import matplotlib\n",
    "import os\n",
    "import math\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from secrets import ALPACA_API_KEY_VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some constant variables, I could put all of this in a seperate config file\n",
    "ALPACA_API_KEY = ALPACA_API_KEY_VAR\n",
    "START_DATE = '2005-01-03'\n",
    "END_DATE = '2020-12-31'\n",
    "# URL for all the tickers on Polygon\n",
    "POLYGON_TICKERS_URL = 'https://api.polygon.io/v2/reference/tickers?page={}&apiKey={}'\n",
    "# URL FOR PRICING DATA - Note, getting pricing that is UNADJUSTED for splits, I will try and adjust those manually\n",
    "POLYGON_AGGS_URL = 'https://api.polygon.io/v2/aggs/ticker/{}/range/1/day/{}/{}?unadjusted=true&apiKey={}'\n",
    "# URL FOR DIVIDEND DATA\n",
    "POLYGON_DIV_URL = 'https://api.polygon.io/v2/reference/dividends/{}?apiKey={}'\n",
    "# URL FOR STOCK SPLITS\n",
    "POLYGON_SPLIT_URL = 'https://api.polygon.io/v2/reference/splits/{}?apiKey={}'\n",
    "#URL FOR TICKER TYPES\n",
    "POLYGON_TYPES_URL = 'https://api.polygon.io/v2/reference/types?apiKey={}'\n",
    "#URL FOR TICKER Info\n",
    "POLYGON_TICKER_INFO_URL = \"https://api.polygon.io/v1/meta/symbols/{}/company?apiKey={}\""
   ]
  },
  {
   "source": [
    "## Ticker Info API"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{\"logo\":\"https://s3.polygon.io/logos/aapl/logo.png\",\"listdate\":\"1990-01-02\",\"cik\":\"320193\",\"bloomberg\":\"EQ0010169500001000\",\"figi\":null,\"lei\":\"HWUPKR0MPOU8FGXBT394\",\"sic\":3571,\"country\":\"usa\",\"industry\":\"Computer Hardware\",\"sector\":\"Technology\",\"marketcap\":908316631180,\"employees\":123000,\"phone\":\"+1 408 996-1010\",\"ceo\":\"Timothy D. Cook\",\"url\":\"http://www.apple.com\",\"description\":\"Apple Inc is designs, manufactures and markets mobile communication and media devices and personal computers, and sells a variety of related software, services, accessories, networking solutions and third-party digital content and applications.\",\"exchange\":\"Nasdaq Global Select\",\"name\":\"Apple Inc.\",\"symbol\":\"AAPL\",\"exchangeSymbol\":\"NGS\",\"hq_address\":\"1 Infinite Loop Cupertino CA, 95014\",\"hq_state\":\"CA\",\"hq_country\":\"USA\",\"type\":\"CS\",\"updated\":\"11/16/2018\",\"tags\":[\"Technology\",\"Consumer Electronics\",\"Computer Hardware\"],\"similar\":[\"MSFT\",\"NOK\",\"IBM\",\"HPQ\",\"GOOGL\",\"BB\",\"XLK\"],\"active\":true}'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "requests.get(POLYGON_TICKER_INFO_URL.format(\"AAPL\", ALPACA_API_KEY)).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all supported tickers from Polygon.io\n",
    "def get_tickers(url = POLYGON_TICKERS_URL):\n",
    "    page = 1\n",
    "\n",
    "    session = requests.Session()\n",
    "    # Initial request to get the ticker count\n",
    "    r = session.get(POLYGON_TICKERS_URL.format(page, ALPACA_API_KEY))\n",
    "    data = r.json()\n",
    "\n",
    "    # This is to figure out how many pages to run pagination \n",
    "    count = data['count']\n",
    "    print('total tickers ' + str(count))\n",
    "    pages = math.ceil(count / data['perPage'])\n",
    "\n",
    "    # Pull in all the pages of tickers\n",
    "    for pages in range (2, pages+1):  # For production\n",
    "    # for pages in range (2, 10):  # For testing\n",
    "        r = session.get(POLYGON_TICKERS_URL.format(page, ALPACA_API_KEY))\n",
    "        data = r.json()\n",
    "        df = pd.DataFrame(data['tickers'])\n",
    "        df.to_csv('data/tickers/{}.csv'.format(page), index=False)\n",
    "        print('Page {} processed'.format(page))\n",
    "        page += 1\n",
    "        \n",
    "    return('Processes {} pages of tickers'.format(page-1))\n",
    "\n",
    "\n",
    "# Stich all of these csv files into one dataframe for analysis\n",
    "def combine_tickers(directory):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for f in os.listdir(directory):\n",
    "        df2 = pd.read_csv('{}/{}'.format(directory, f))\n",
    "        df = df.append(df2)\n",
    "    \n",
    "    # Read out a copy of the file to a csv for later analysis\n",
    "    df.set_index('ticker', inplace=True)\n",
    "    df.drop_duplicates()  # Just in case any tickers get pulled twice\n",
    "    df.to_csv('polygon_tickers.csv')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_us_exch(ticker_df):\n",
    "    \n",
    "    # Keep only U.S. Dollar denominated securities\n",
    "    df = ticker_df[(ticker_df.currency == 'USD') & (ticker_df.locale == 'US')]\n",
    "    # Keep only the primary U.S. exchanges\n",
    "    exch = ['AMX','ARCA','BATS','NASDAQ','NSC','NYE']\n",
    "    df = df[df['primaryExch'].isin(exch)]\n",
    "    # Filter out preferred stock, american depositry receipts, closed end funds, reit\n",
    "    stockTypes = ['PFD','ADR','CEF','MLP','REIT','RIGHT','UNIT','WRT']\n",
    "    df = df[df['type'].isin(stockTypes) == False]\n",
    "    \n",
    "    df.to_csv('polygon_tickers_us.csv')\n",
    "\n",
    "    # Create a list of symbols to loop thru\n",
    "    symbols = df.index.tolist()\n",
    "\n",
    "    return symbols\n",
    "\n",
    "\n",
    "# Get the aggregated bars for the symbols I need\n",
    "def get_bars(symbolslist, outdir, start, end):\n",
    "\n",
    "    session = requests.Session()\n",
    "    # In case I run into issues, retry my connection\n",
    "    retries = Retry(total=5, backoff_factor=0.1, status_forcelist=[ 500, 502, 503, 504 ])\n",
    "\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "    count = 0\n",
    "    \n",
    "    barlog = open(\"barlog.txt\", \"w\")\n",
    "    \n",
    "    for symbol in symbolslist:\n",
    "        try:\n",
    "            r = session.get(POLYGON_AGGS_URL.format(symbol, start, end, ALPACA_API_KEY))\n",
    "            if r:\n",
    "                data = r.json()\n",
    "            \n",
    "                # create a pandas dataframe from the information\n",
    "                if data['queryCount'] > 1:\n",
    "                    df = pd.DataFrame(data['results'])\n",
    "                    df['date'] = pd.to_datetime(df['t'], unit='ms')\n",
    "                    df['date'] =  df['date'].dt.date.astype(str)\n",
    "                    df.set_index('date', inplace=True)\n",
    "                    df['symbol'] = symbol\n",
    "\n",
    "                    df.drop(columns=['vw', 't', 'n'], inplace=True)\n",
    "                    df.rename(columns={'v': 'volume', 'o': 'open', 'c': 'close', 'h': 'high', 'l': 'low'}, inplace=True)\n",
    "\n",
    "                    df.to_csv('{}/{}.csv'.format(outdir, symbol), index=True)\n",
    "                    count += 1\n",
    "\n",
    "                    # Logging, I could write a short method for this to reuse\n",
    "                    msg = (symbol + ' file created with record count ' + str(data['queryCount']))\n",
    "                    print(msg)\n",
    "                    barlog.write(msg)\n",
    "                    barlog.write(\"\\n\")\n",
    "\n",
    "                else:\n",
    "                    msg = ('No data for symbol ' + str(symbol))\n",
    "                    print(msg)\n",
    "                    barlog.write(msg)\n",
    "                    barlog.write(\"\\n\")\n",
    "            else:\n",
    "                msg = ('No response for symbol ' + str(symbol))\n",
    "                print(msg)\n",
    "                barlog.write(msg)\n",
    "                barlog.write(\"\\n\")\n",
    "        # Raise exception but continue           \n",
    "        except:\n",
    "            msg = ('****** exception raised for symbol ' + str(symbol))\n",
    "            print(msg)\n",
    "            barlog.write(msg)\n",
    "            barlog.write(\"\\n\")\n",
    "    \n",
    "    barlog.close()\n",
    "    return ('{} file were exported'.format(count))\n",
    "\n",
    "\n",
    "# Define a function to pull in the splits data\n",
    "def get_splits(symbolslist, outdir):\n",
    "\n",
    "    session = requests.Session()\n",
    "    # In case I run into issues, retry my connection\n",
    "    retries = Retry(total=5, backoff_factor=0.1, status_forcelist=[ 500, 502, 503, 504 ])\n",
    "\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "    count = 0\n",
    "    \n",
    "    # Get the split data\n",
    "    for symbol in symbolslist:\n",
    "        try:\n",
    "            r = session.get(POLYGON_SPLIT_URL.format(symbol, ALPACA_API_KEY))\n",
    "            if r:\n",
    "                data = r.json()\n",
    "                if data['count'] > 0:\n",
    "                    df = pd.DataFrame(data['results'])\n",
    "                    df.rename(columns={'exDate': 'date', 'declaredDate': 'splitDeclaredDate'}, inplace=True)\n",
    "                    df.drop(columns=['paymentDate'], inplace=True)\n",
    "                    df.set_index('date', inplace=True)\n",
    "                    df.to_csv('{}/{}.csv'.format(outdir, symbol), index=True)\n",
    "                    \n",
    "                    print('split file for ' + symbol + ' ' + str(data['count']))\n",
    "                    count += 1\n",
    "                else:\n",
    "                    print('No data for symbol ' + str(symbol))\n",
    "            else:\n",
    "                print('No response for symbol ' + str(symbol))\n",
    "        # Raise exception but continue           \n",
    "        except:\n",
    "            print('****** exception raised for symbol ' + str(symbol))\n",
    "            \n",
    "    return ('{} file were exported'.format(count))\n",
    "\n",
    "\n",
    "# Fix erroneous splits from a correction file manually created\n",
    "def fix_splits(splitpath):\n",
    "    # Get the split corrections to overwrite\n",
    "    correct_df = pd.read_csv('split_corrections.csv')\n",
    "    # create a list of symbols to fix\n",
    "    symbols = correct_df['ticker'].tolist()\n",
    "    # remove duplicates\n",
    "    symbols = list(dict.fromkeys(symbols))\n",
    "\n",
    "    # for symbol in symbols:\n",
    "    for symbol in symbols:\n",
    "        print(symbol)\n",
    "\n",
    "    # get any splits\n",
    "        if os.path.isfile('{}/{}.csv'.format(splitpath, symbol)):\n",
    "            df = pd.read_csv('{}/{}.csv'.format(splitpath, symbol))\n",
    "            print(df)\n",
    "            df = pd.merge(df, correct_df, how='left', left_on=['date', 'ticker'], right_on=['date', 'ticker'])\n",
    "            \n",
    "            for index, row in df.iterrows():\n",
    "                # Adjust bad dates\n",
    "                if not pd.isnull(row.date_adj):\n",
    "                    df.loc[index, 'date'] = row.date_adj\n",
    "                # Adjust bad ratios\n",
    "                if not pd.isnull(row.ratio_adj):\n",
    "                    df.loc[index, 'ratio'] = row.ratio_adj\n",
    "                else:\n",
    "                    df.loc[index, 'ratio'] = row.ratio_x\n",
    "            \n",
    "            # Format the dataframe for export\n",
    "            df = df[['date', 'ticker', 'ratio']]\n",
    "            df.set_index('date', inplace=True)\n",
    "            print(df)\n",
    "\n",
    "            # Overwrite the file with this new file\n",
    "            df.to_csv('{}/{}.csv'.format(splitpath, symbol))\n",
    "            print('Split file for {} corrected'.format(symbol))\n",
    "            \n",
    "        else:\n",
    "            print('no file found')\n",
    "                \n",
    "    return ('Split file corrections complete')\n",
    "\n",
    "\n",
    "# Define a function to pull in the splits data\n",
    "def get_divs(symbolslist, outdir):\n",
    "\n",
    "    session = requests.Session()\n",
    "    count = 0\n",
    "    \n",
    "    # Get the split data\n",
    "    for symbol in symbolslist: # ['AAPL']:\n",
    "        r = session.get(POLYGON_DIV_URL.format(symbol, ALPACA_API_KEY))\n",
    "        data = r.json()\n",
    "        if data['count'] > 0:\n",
    "            df = pd.DataFrame(data['results'])\n",
    "            # df.rename(columns={'paymentDate': 'date'}, inplace=True)\n",
    "            df.rename(columns={'exDate': 'date', 'amount': 'dividend',\n",
    "                               'paymentDate': 'divPaymentDate',\n",
    "                               'recordDate': 'divRecordDate',\n",
    "                               'declaredDate': 'divDeclaredDate'}, inplace=True)\n",
    "            df.set_index('date', inplace=True)\n",
    "            df = df.groupby(df.index).first()\n",
    "            df.to_csv('{}/{}.csv'.format(outdir, symbol), index=True)\n",
    "            \n",
    "            print('div file for ' + symbol + ' ' + str(data['count']))\n",
    "            count += 1\n",
    "            \n",
    "    return ('{} file were exported'.format(count))\n",
    "\n",
    "\n",
    "# Combine bars, splits and dividend\n",
    "def combine_bars(barpath, splitpath, divpath):\n",
    "\n",
    "    count = 0\n",
    "    for f in os.listdir(barpath):\n",
    "        \n",
    "        symbol = f[:-4]\n",
    "        print(symbol)\n",
    "        \n",
    "        # Get the bar data\n",
    "        if os.path.isfile('{}/{}.csv'.format(barpath, symbol)):\n",
    "            bars = pd.read_csv('{}/{}.csv'.format(barpath, symbol), index_col='date')\n",
    "            \n",
    "            # get any splits\n",
    "            if os.path.isfile('{}/{}.csv'.format(splitpath, symbol)):\n",
    "                splits = pd.read_csv('{}/{}.csv'.format(splitpath, symbol), index_col='date')\n",
    "                splits.drop(columns=['ticker'], inplace=True)\n",
    "                \n",
    "                bars = bars.merge(splits, left_index=True, right_index=True, how='left')\n",
    "\n",
    "            else:\n",
    "                \n",
    "                bars = bars\n",
    "            \n",
    "            # get any dividend payments\n",
    "            if os.path.isfile('{}/{}.csv'.format(divpath, symbol)):\n",
    "                divs = pd.read_csv('{}/{}.csv'.format(divpath, symbol), index_col='date')\n",
    "                divs.drop(columns=['ticker'], inplace=True)\n",
    "            \n",
    "                bars = bars.merge(divs, left_index=True, right_index=True, how='left')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                bars = bars\n",
    "                \n",
    "            # Export bars \n",
    "            bars.to_csv('data/bars_adj/{}.csv'.format(symbol))\n",
    "            count += 1\n",
    "        \n",
    "    return ('{} adjusted bar file were exported'.format(count))\n",
    "\n",
    "\n",
    "# Adjust the OHLCV data for stock splits\n",
    "def adj_bars(directory):\n",
    "\n",
    "    count = 0\n",
    "    for f in os.listdir(directory):\n",
    "\n",
    "        df = pd.read_csv('{}/{}'.format(directory, f), index_col='date')\n",
    "        \n",
    "        if 'ratio' in df.columns:\n",
    "            df['ratio_adj'] = df['ratio']\n",
    "        else:\n",
    "             df['ratio_adj'] = 1\n",
    "\n",
    "        # Create a split factor, shifted to the day earlier.  Also, fill in any missing factors with 1\n",
    "        df['split_factor'] = (1 / df['ratio_adj'].shift(-1)).fillna(1)\n",
    "        #  Create a cumulative product of the splits, in reverse order using the []::-1]\n",
    "        df['split_factor'] = df['split_factor'][::-1].cumprod()\n",
    "\n",
    "        # Adjust the various OHLCV metrics\n",
    "        df['volume_adj'] = df['volume'] * df['split_factor']\n",
    "        df['open_adj'] = df['open'] / df['split_factor']\n",
    "        df['close_adj'] = df['close'] / df['split_factor']\n",
    "        df['high_adj'] = df['high'] / df['split_factor']\n",
    "        df['low_adj'] = df['low'] / df['split_factor']\n",
    "        df['dollar_volume'] = df['volume'] * df['close']\n",
    "\n",
    "        df.to_csv('{}/{}'.format(directory, f))\n",
    "        count += 1\n",
    "        \n",
    "    return ('{} files was adjusted'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Name       Sector Symbol\n",
       "0           3M Company  Industrials    MMM\n",
       "1      A.O. Smith Corp  Industrials    AOS\n",
       "2  Abbott Laboratories  Health Care    ABT"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Sector</th>\n      <th>Symbol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3M Company</td>\n      <td>Industrials</td>\n      <td>MMM</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A.O. Smith Corp</td>\n      <td>Industrials</td>\n      <td>AOS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abbott Laboratories</td>\n      <td>Health Care</td>\n      <td>ABT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "sp_constituents = pd.read_json(\"https://datahub.io/core/s-and-p-500-companies/r/constituents.json\")\n",
    "sp_constituents.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reated with record count 4008\n",
      "ADBE file created with record count 4028\n",
      "AAP file created with record count 4028\n",
      "AMD file created with record count 4028\n",
      "AES file created with record count 4028\n",
      "AFL file created with record count 4028\n",
      "A file created with record count 4028\n",
      "APD file created with record count 4028\n",
      "AKAM file created with record count 4028\n",
      "ALK file created with record count 4028\n",
      "ALB file created with record count 4028\n",
      "ARE file created with record count 4028\n",
      "ALXN file created with record count 4028\n",
      "ALGN file created with record count 4028\n",
      "ALLE file created with record count 1784\n",
      "LNT file created with record count 4028\n",
      "ALL file created with record count 4028\n",
      "GOOGL file created with record count 1700\n",
      "GOOG file created with record count 4028\n",
      "MO file created with record count 4028\n",
      "AMZN file created with record count 4028\n",
      "AMCR file created with record count 1010\n",
      "AEE file created with record count 4028\n",
      "AAL file created with record count 1779\n",
      "AEP file created with record count 4028\n",
      "AXP file created with record count 4028\n",
      "AIG file created with record count 4028\n",
      "AMT file created with record count 4028\n",
      "AWK file created with record count 3197\n",
      "AMP file created with record count 3839\n",
      "ABC file created with record count 4028\n",
      "AME file created with record count 4028\n",
      "AMGN file created with record count 4028\n",
      "APH file created with record count 4028\n",
      "ADI file created with record count 4028\n",
      "ANSS file created with record count 4028\n",
      "ANTM file created with record count 1531\n",
      "AON file created with record count 2791\n",
      "APA file created with record count 4028\n",
      "AIV file created with record count 4028\n",
      "AAPL file created with record count 4028\n",
      "AMAT file created with record count 4028\n",
      "APTV file created with record count 774\n",
      "ADM file created with record count 4028\n",
      "ANET file created with record count 1787\n",
      "AJG file created with record count 4028\n",
      "AIZ file created with record count 4028\n",
      "T file created with record count 4021\n",
      "ATO file created with record count 4028\n",
      "ADSK file created with record count 4028\n",
      "ADP file created with record count 4028\n",
      "AZO file created with record count 4028\n",
      "AVB file created with record count 4028\n",
      "AVY file created with record count 4028\n",
      "BKR file created with record count 2514\n",
      "BLL file created with record count 4028\n",
      "BAC file created with record count 4028\n",
      "BAX file created with record count 4028\n",
      "BDX file created with record count 4028\n",
      "BRK.B file created with record count 4028\n",
      "BBY file created with record count 4028\n",
      "BIO file created with record count 4028\n",
      "BIIB file created with record count 4025\n",
      "BLK file created with record count 4028\n",
      "BA file created with record count 4028\n",
      "BKNG file created with record count 718\n",
      "BWA file created with record count 4028\n",
      "BXP file created with record count 4028\n",
      "BSX file created with record count 4028\n",
      "BMY file created with record count 4028\n",
      "AVGO file created with record count 2872\n",
      "BR file created with record count 3778\n",
      "BF.B file created with record count 4028\n",
      "CHRW file created with record count 4008\n",
      "COG file created with record count 4028\n",
      "CDNS file created with record count 3819\n",
      "CPB file created with record count 4028\n",
      "COF file created with record count 4028\n",
      "CAH file created with record count 4028\n",
      "KMX file created with record count 4028\n",
      "CCL file created with record count 4028\n",
      "CARR file created with record count 189\n",
      "CAT file created with record count 4028\n",
      "CBOE file created with record count 2657\n",
      "CBRE file created with record count 703\n",
      "CDW file created with record count 1893\n",
      "CE file created with record count 4015\n",
      "CNC file created with record count 4028\n",
      "CNP file created with record count 4028\n",
      "CTL file created with record count 3955\n",
      "CERN file created with record count 4028\n",
      "CF file created with record count 3875\n",
      "SCHW file created with record count 3784\n",
      "CHTR file created with record count 3666\n",
      "CVX file created with record count 4028\n",
      "CMG file created with record count 3760\n",
      "CB file created with record count 4028\n",
      "CHD file created with record count 4028\n",
      "CI file created with record count 4028\n",
      "CINF file created with record count 4028\n",
      "CTAS file created with record count 4028\n",
      "CSCO file created with record count 4028\n",
      "C file created with record count 4028\n",
      "CFG file created with record count 1580\n",
      "CTXS file created with record count 4028\n",
      "CME file created with record count 4028\n",
      "CMS file created with record count 4028\n",
      "KO file created with record count 4028\n",
      "CTSH file created with record count 4028\n",
      "CL file created with record count 4028\n",
      "CMCSA file created with record count 4028\n",
      "CMA file created with record count 4028\n",
      "CAG file created with record count 4028\n",
      "CXO file created with record count 3378\n",
      "COP file created with record count 4028\n",
      "ED file created with record count 4028\n",
      "STZ file created with record count 4028\n",
      "CPRT file created with record count 4028\n",
      "GLW file created with record count 4028\n",
      "CTVA file created with record count 401\n",
      "COST file created with record count 4028\n",
      "COTY file created with record count 1903\n",
      "CCI file created with record count 4028\n",
      "CSX file created with record count 4028\n",
      "CMI file created with record count 4028\n",
      "CVS file created with record count 4028\n",
      "DHI file created with record count 4028\n",
      "DHR file created with record count 4028\n",
      "DRI file created with record count 4028\n",
      "DVA file created with record count 4028\n",
      "DE file created with record count 4028\n",
      "DAL file created with record count 3639\n",
      "XRAY file created with record count 4028\n",
      "DVN file created with record count 4028\n",
      "DXCM file created with record count 3957\n",
      "FANG file created with record count 2068\n",
      "DLR file created with record count 4028\n",
      "DFS file created with record count 3629\n",
      "DISCA file created with record count 3870\n",
      "DISCK file created with record count 3094\n",
      "DISH file created with record count 4028\n",
      "DG file created with record count 3433\n",
      "DLTR file created with record count 4028\n",
      "D file created with record count 4028\n",
      "DPZ file created with record count 4028\n",
      "DOV file created with record count 4028\n",
      "DOW file created with record count 3632\n",
      "DTE file created with record count 4028\n",
      "DUK file created with record count 4028\n",
      "DRE file created with record count 4028\n",
      "DD file created with record count 3590\n",
      "DXC file created with record count 945\n",
      "ETFC file created with record count 3445\n",
      "EMN file created with record count 4028\n",
      "ETN file created with record count 4028\n",
      "EBAY file created with record count 4028\n",
      "ECL file created with record count 4028\n",
      "EIX file created with record count 4028\n",
      "EW file created with record count 4028\n",
      "EA file created with record count 2273\n",
      "EMR file created with record count 4028\n",
      "ETR file created with record count 4028\n",
      "EOG file created with record count 4028\n",
      "EFX file created with record count 4028\n",
      "EQIX file created with record count 4028\n",
      "EQR file created with record count 4028\n",
      "ESS file created with record count 4028\n",
      "EL file created with record count 4028\n",
      "RE file created with record count 4028\n",
      "EVRG file created with record count 650\n",
      "ES file created with record count 2869\n",
      "EXC file created with record count 4028\n",
      "EXPE file created with record count 3877\n",
      "EXPD file created with record count 4028\n",
      "EXR file created with record count 4028\n",
      "XOM file created with record count 4028\n",
      "FFIV file created with record count 4028\n",
      "FB file created with record count 2170\n",
      "FAST file created with record count 4028\n",
      "FRT file created with record count 4028\n",
      "FDX file created with record count 4028\n",
      "FIS file created with record count 3756\n",
      "FITB file created with record count 4028\n",
      "FRC file created with record count 3321\n",
      "FE file created with record count 4028\n",
      "FISV file created with record count 4028\n",
      "FLT file created with record count 3456\n",
      "FLIR file created with record count 4028\n",
      "FLS file created with record count 4028\n",
      "FMC file created with record count 4028\n",
      "F file created with record count 4028\n",
      "FTNT file created with record count 2799\n",
      "FTV file created with record count 1133\n",
      "FBHS file created with record count 2327\n",
      "FOXA file created with record count 1891\n",
      "FOX file created with record count 1945\n",
      "BEN file created with record count 4028\n",
      "FCX file created with record count 4028\n",
      "GPS file created with record count 4028\n",
      "GRMN file created with record count 4028\n",
      "IT file created with record count 4028\n",
      "GD file created with record count 4028\n",
      "GE file created with record count 4028\n",
      "GIS file created with record count 4028\n",
      "GM file created with record count 3657\n",
      "GPC file created with record count 4028\n",
      "GILD file created with record count 4028\n",
      "GPN file created with record count 4028\n",
      "GL file created with record count 353\n",
      "GS file created with record count 4028\n",
      "GWW file created with record count 4028\n",
      "HRB file created with record count 4028\n",
      "HAL file created with record count 4028\n",
      "HBI file created with record count 3606\n",
      "HIG file created with record count 4028\n",
      "HAS file created with record count 4028\n",
      "HCA file created with record count 2946\n",
      "PEAK file created with record count 1116\n",
      "HSIC file created with record count 4028\n",
      "HES file created with record count 3689\n",
      "HPE file created with record count 1301\n",
      "HLT file created with record count 2484\n",
      "HFC file created with record count 2392\n",
      "HOLX file created with record count 4028\n",
      "HD file created with record count 4028\n",
      "HON file created with record count 4028\n",
      "HRL file created with record count 4028\n",
      "HST file created with record count 3704\n",
      "HWM file created with record count 191\n",
      "HPQ file created with record count 4028\n",
      "HUM file created with record count 4028\n",
      "HBAN file created with record count 4028\n",
      "HII file created with record count 2456\n",
      "IEX file created with record count 4028\n",
      "IDXX file created with record count 4028\n",
      "INFO file created with record count 2032\n",
      "ITW file created with record count 4028\n",
      "ILMN file created with record count 4028\n",
      "INCY file created with record count 4028\n",
      "IR file created with record count 4028\n",
      "INTC file created with record count 4028\n",
      "ICE file created with record count 3807\n",
      "IBM file created with record count 4028\n",
      "IFF file created with record count 4028\n",
      "IP file created with record count 4028\n",
      "IPG file created with record count 4028\n",
      "INTU file created with record count 4028\n",
      "ISRG file created with record count 4028\n",
      "IVZ file created with record count 3427\n",
      "IPGP file created with record count 3537\n",
      "IQV file created with record count 787\n",
      "IRM file created with record count 4028\n",
      "JBHT file created with record count 4028\n",
      "JKHY file created with record count 4028\n",
      "J file created with record count 268\n",
      "SJM file created with record count 4028\n",
      "JNJ file created with record count 4028\n",
      "JCI file created with record count 4028\n",
      "JPM file created with record count 4028\n",
      "JNPR file created with record count 4028\n",
      "KSU file created with record count 4028\n",
      "K file created with record count 4028\n",
      "KEY file created with record count 4028\n",
      "KEYS file created with record count 2252\n",
      "KMB file created with record count 4028\n",
      "KIM file created with record count 4028\n",
      "KMI file created with record count 3094\n",
      "KLAC file created with record count 4028\n",
      "KSS file created with record count 4028\n",
      "KHC file created with record count 1385\n",
      "KR file created with record count 4028\n",
      "LB file created with record count 3418\n",
      "LHX file created with record count 381\n",
      "LH file created with record count 4028\n",
      "LRCX file created with record count 4028\n",
      "LW file created with record count 1042\n",
      "LVS file created with record count 4028\n",
      "LEG file created with record count 4028\n",
      "LDOS file created with record count 1828\n",
      "LEN file created with record count 4028\n",
      "LLY file created with record count 4028\n",
      "LNC file created with record count 4028\n",
      "LIN file created with record count 1180\n",
      "LYV file created with record count 3782\n",
      "LKQ file created with record count 2168\n",
      "LMT file created with record count 4028\n",
      "L file created with record count 3495\n",
      "LOW file created with record count 4028\n",
      "LYB file created with record count 2572\n",
      "MTB file created with record count 4028\n",
      "MRO file created with record count 4028\n",
      "MPC file created with record count 2393\n",
      "MKTX file created with record count 4028\n",
      "MAR file created with record count 4028\n",
      "MMC file created with record count 4028\n",
      "MLM file created with record count 4028\n",
      "MAS file created with record count 4028\n",
      "MA file created with record count 3677\n",
      "MXIM file created with record count 3771\n",
      "MKC file created with record count 4028\n",
      "MCD file created with record count 4028\n",
      "MCK file created with record count 4028\n",
      "MDT file created with record count 4028\n",
      "MRK file created with record count 4028\n",
      "MET file created with record count 4028\n",
      "MTD file created with record count 4028\n",
      "MGM file created with record count 4013\n",
      "MCHP file created with record count 4028\n",
      "MU file created with record count 4028\n",
      "MSFT file created with record count 4028\n",
      "MAA file created with record count 4028\n",
      "MHK file created with record count 4028\n",
      "TAP file created with record count 4002\n",
      "MDLZ file created with record count 2076\n",
      "MNST file created with record count 3232\n",
      "MCO file created with record count 4028\n",
      "MS file created with record count 4010\n",
      "MSI file created with record count 3268\n",
      "MSCI file created with record count 2643\n",
      "MYL file created with record count 3997\n",
      "NDAQ file created with record count 4001\n",
      "NOV file created with record count 3980\n",
      "NTAP file created with record count 4028\n",
      "NFLX file created with record count 4028\n",
      "NWL file created with record count 4028\n",
      "NEM file created with record count 4028\n",
      "NWSA file created with record count 3024\n",
      "NWS file created with record count 4028\n",
      "NEE file created with record count 2651\n",
      "NLSN file created with record count 2501\n",
      "NKE file created with record count 4028\n",
      "NI file created with record count 4028\n",
      "NBL file created with record count 3966\n",
      "NSC file created with record count 4028\n",
      "NTRS file created with record count 4028\n",
      "NOC file created with record count 4028\n",
      "NLOK file created with record count 292\n",
      "NCLH file created with record count 2003\n",
      "NRG file created with record count 4028\n",
      "NUE file created with record count 4028\n",
      "NVDA file created with record count 4028\n",
      "NVR file created with record count 4028\n",
      "ORLY file created with record count 4028\n",
      "OXY file created with record count 4028\n",
      "ODFL file created with record count 4028\n",
      "OMC file created with record count 4028\n",
      "OKE file created with record count 4028\n",
      "ORCL file created with record count 4028\n",
      "OTIS file created with record count 189\n",
      "PCAR file created with record count 4028\n",
      "PKG file created with record count 4028\n",
      "PH file created with record count 4028\n",
      "PAYX file created with record count 4028\n",
      "PAYC file created with record count 1692\n",
      "PYPL file created with record count 1375\n",
      "PNR file created with record count 4028\n",
      "PBCT file created with record count 4008\n",
      "PEP file created with record count 4028\n",
      "PKI file created with record count 4028\n",
      "PRGO file created with record count 4028\n",
      "PFE file created with record count 4028\n",
      "PM file created with record count 3214\n",
      "PSX file created with record count 2183\n",
      "PNW file created with record count 4028\n",
      "PXD file created with record count 4028\n",
      "PNC file created with record count 4028\n",
      "PPG file created with record count 4028\n",
      "PPL file created with record count 4028\n",
      "PFG file created with record count 4028\n",
      "PG file created with record count 4028\n",
      "PGR file created with record count 4028\n",
      "PLD file created with record count 4028\n",
      "PRU file created with record count 4028\n",
      "PEG file created with record count 4028\n",
      "PSA file created with record count 4028\n",
      "PHM file created with record count 4028\n",
      "PVH file created with record count 4028\n",
      "QRVO file created with record count 1511\n",
      "QCOM file created with record count 4028\n",
      "PWR file created with record count 4028\n",
      "DGX file created with record count 4028\n",
      "RL file created with record count 4028\n",
      "RJF file created with record count 4028\n",
      "RTX file created with record count 463\n",
      "O file created with record count 4028\n",
      "REG file created with record count 4028\n",
      "REGN file created with record count 4027\n",
      "RF file created with record count 4028\n",
      "RSG file created with record count 4028\n",
      "RMD file created with record count 4028\n",
      "RHI file created with record count 4028\n",
      "ROK file created with record count 4028\n",
      "ROL file created with record count 4028\n",
      "ROP file created with record count 4028\n",
      "ROST file created with record count 4028\n",
      "RCL file created with record count 4028\n",
      "SPGI file created with record count 1179\n",
      "CRM file created with record count 4028\n",
      "SBAC file created with record count 4028\n",
      "SLB file created with record count 4028\n",
      "STX file created with record count 4028\n",
      "SEE file created with record count 4028\n",
      "SRE file created with record count 4028\n",
      "NOW file created with record count 2842\n",
      "SHW file created with record count 4028\n",
      "SPG file created with record count 4028\n",
      "SWKS file created with record count 4028\n",
      "SLG file created with record count 4028\n",
      "SNA file created with record count 4028\n",
      "SO file created with record count 4028\n",
      "LUV file created with record count 4028\n",
      "SWK file created with record count 4028\n",
      "SBUX file created with record count 4028\n",
      "STT file created with record count 4028\n",
      "STE file created with record count 4028\n",
      "SYK file created with record count 4028\n",
      "SIVB file created with record count 3927\n",
      "SYF file created with record count 1618\n",
      "SNPS file created with record count 4028\n",
      "SYY file created with record count 4028\n",
      "TMUS file created with record count 1933\n",
      "TROW file created with record count 4028\n",
      "TTWO file created with record count 4028\n",
      "TPR file created with record count 939\n",
      "TGT file created with record count 4028\n",
      "TEL file created with record count 3401\n",
      "FTI file created with record count 4028\n",
      "TDY file created with record count 4028\n",
      "TFX file created with record count 4028\n",
      "TXN file created with record count 4028\n",
      "TXT file created with record count 4028\n",
      "BK file created with record count 4028\n",
      "CLX file created with record count 4028\n",
      "COO file created with record count 4028\n",
      "HSY file created with record count 4028\n",
      "MOS file created with record count 4028\n",
      "TRV file created with record count 3488\n",
      "DIS file created with record count 4028\n",
      "TMO file created with record count 4028\n",
      "TIF file created with record count 4028\n",
      "TJX file created with record count 4028\n",
      "TSCO file created with record count 4028\n",
      "TT file created with record count 357\n",
      "TDG file created with record count 3727\n",
      "TFC file created with record count 1965\n",
      "TWTR file created with record count 2420\n",
      "TYL file created with record count 4028\n",
      "TSN file created with record count 4028\n",
      "USB file created with record count 4028\n",
      "UDR file created with record count 4028\n",
      "ULTA file created with record count 3320\n",
      "UAA file created with record count 1024\n",
      "UA file created with record count 3534\n",
      "UNP file created with record count 4028\n",
      "UAL file created with record count 2581\n",
      "UNH file created with record count 4028\n",
      "UPS file created with record count 4028\n",
      "URI file created with record count 4028\n",
      "UHS file created with record count 4028\n",
      "UNM file created with record count 4028\n",
      "VLO file created with record count 4028\n",
      "VAR file created with record count 4028\n",
      "VTR file created with record count 4028\n",
      "VRSN file created with record count 4028\n",
      "VRSK file created with record count 2829\n",
      "VZ file created with record count 4028\n",
      "VRTX file created with record count 4026\n",
      "VFC file created with record count 4028\n",
      "VIAC file created with record count 981\n",
      "V file created with record count 3621\n",
      "VNO file created with record count 4028\n",
      "VMC file created with record count 4028\n",
      "WRB file created with record count 3203\n",
      "WAB file created with record count 4028\n",
      "WBA file created with record count 1512\n",
      "WMT file created with record count 4028\n",
      "WM file created with record count 3814\n",
      "WAT file created with record count 4028\n",
      "WEC file created with record count 4028\n",
      "WFC file created with record count 4028\n",
      "WELL file created with record count 717\n",
      "WST file created with record count 4028\n",
      "WDC file created with record count 4028\n",
      "WU file created with record count 3588\n",
      "WRK file created with record count 1386\n",
      "WY file created with record count 4028\n",
      "WHR file created with record count 4028\n",
      "WMB file created with record count 4028\n",
      "WLTW file created with record count 1258\n",
      "WYNN file created with record count 4028\n",
      "XEL file created with record count 4028\n",
      "XRX file created with record count 4028\n",
      "XLNX file created with record count 4028\n",
      "XYL file created with record count 2307\n",
      "YUM file created with record count 4028\n",
      "ZBRA file created with record count 4028\n",
      "ZBH file created with record count 1389\n",
      "ZION file created with record count 4028\n",
      "ZTS file created with record count 1994\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'505 file were exported'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#%%  Filter down to the tickers I'm interestead in (this could also be done by modifying get_tickers)\n",
    "# symbols = filter_us_exch(symbols)\n",
    "\n",
    "symbols = list(sp_constituents.iloc[:, -1])\n",
    "\n",
    "#%% Get all the aggregated bar/pricing data for each symbol in the filtered list\n",
    "get_bars(symbols, 'data/bars', START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "split file for MMM 1\n",
      "split file for AOS 4\n",
      "split file for ABT 3\n",
      "No data for symbol ABBV\n",
      "split file for ABMD 1\n",
      "No data for symbol ACN\n",
      "split file for ATVI 6\n",
      "split file for ADBE 3\n",
      "split file for AAP 2\n",
      "split file for AMD 1\n",
      "split file for AES 1\n",
      "split file for AFL 4\n",
      "No data for symbol A\n",
      "split file for APD 1\n",
      "No data for symbol AKAM\n",
      "split file for ALK 2\n",
      "split file for ALB 1\n",
      "split file for ARE 1\n",
      "split file for ALXN 2\n",
      "No data for symbol ALGN\n",
      "No data for symbol ALLE\n",
      "split file for LNT 1\n",
      "split file for ALL 1\n",
      "split file for GOOGL 1\n",
      "split file for GOOG 2\n",
      "No data for symbol MO\n",
      "split file for AMZN 3\n",
      "No data for symbol AMCR\n",
      "No data for symbol AEE\n",
      "No data for symbol AAL\n",
      "No data for symbol AEP\n",
      "split file for AXP 2\n",
      "split file for AIG 4\n",
      "No data for symbol AMT\n",
      "No data for symbol AWK\n",
      "No data for symbol AMP\n",
      "split file for ABC 3\n",
      "split file for AME 4\n",
      "split file for AMGN 2\n",
      "split file for APH 4\n",
      "split file for ADI 1\n",
      "split file for ANSS 2\n",
      "split file for ANTM 1\n",
      "split file for AON 1\n",
      "split file for APA 3\n",
      "split file for AIV 3\n",
      "split file for AAPL 4\n",
      "split file for AMAT 2\n",
      "No data for symbol APTV\n",
      "split file for ADM 4\n",
      "No data for symbol ANET\n",
      "split file for AJG 2\n",
      "No data for symbol AIZ\n",
      "split file for T 1\n",
      "No data for symbol ATO\n",
      "split file for ADSK 2\n",
      "split file for ADP 2\n",
      "No data for symbol AZO\n",
      "split file for AVB 1\n",
      "No data for symbol AVY\n",
      "No data for symbol BKR\n",
      "split file for BLL 4\n",
      "split file for BAC 1\n",
      "split file for BAX 2\n",
      "split file for BDX 1\n",
      "split file for BRK.B 1\n",
      "split file for BBY 4\n",
      "split file for BIO 1\n",
      "split file for BIIB 2\n",
      "No data for symbol BLK\n",
      "No data for symbol BA\n",
      "split file for BKNG 1\n",
      "split file for BWA 3\n",
      "No data for symbol BXP\n",
      "split file for BSX 2\n",
      "split file for BMY 2\n",
      "No data for symbol AVGO\n",
      "No data for symbol BR\n",
      "split file for BF.B 3\n",
      "split file for CHRW 2\n",
      "split file for COG 4\n",
      "No data for symbol CDNS\n",
      "No data for symbol CPB\n",
      "split file for COF 1\n",
      "split file for CAH 2\n",
      "split file for KMX 1\n",
      "split file for CCL 1\n",
      "No data for symbol CARR\n",
      "split file for CAT 1\n",
      "No data for symbol CBOE\n",
      "split file for CBRE 1\n",
      "No data for symbol CDW\n",
      "No data for symbol CE\n",
      "split file for CNC 4\n",
      "split file for CNP 1\n",
      "split file for CTL 2\n",
      "split file for CERN 3\n",
      "split file for CF 1\n",
      "split file for SCHW 3\n",
      "No data for symbol CHTR\n",
      "split file for CVX 1\n",
      "No data for symbol CMG\n",
      "split file for CB 2\n",
      "split file for CHD 4\n",
      "split file for CI 2\n",
      "split file for CINF 3\n",
      "split file for CTAS 1\n",
      "split file for CSCO 3\n",
      "split file for C 3\n",
      "No data for symbol CFG\n",
      "split file for CTXS 4\n",
      "split file for CME 1\n",
      "No data for symbol CMS\n",
      "split file for KO 1\n",
      "split file for CTSH 5\n",
      "split file for CL 2\n",
      "split file for CMCSA 3\n",
      "split file for CMA 1\n",
      "No data for symbol CAG\n",
      "No data for symbol CXO\n",
      "split file for COP 2\n",
      "No data for symbol ED\n",
      "split file for STZ 3\n",
      "split file for CPRT 6\n",
      "split file for GLW 1\n",
      "No data for symbol CTVA\n",
      "split file for COST 1\n",
      "No data for symbol COTY\n",
      "No data for symbol CCI\n",
      "split file for CSX 2\n",
      "split file for CMI 2\n",
      "split file for CVS 2\n",
      "split file for DHI 5\n",
      "split file for DHR 3\n",
      "split file for DRI 1\n",
      "split file for DVA 2\n",
      "split file for DE 1\n",
      "No data for symbol DAL\n",
      "split file for XRAY 2\n",
      "split file for DVN 1\n",
      "No data for symbol DXCM\n",
      "No data for symbol FANG\n",
      "No data for symbol DLR\n",
      "No data for symbol DFS\n",
      "No data for symbol DISCA\n",
      "No data for symbol DISCK\n",
      "split file for DISH 3\n",
      "No data for symbol DG\n",
      "split file for DLTR 4\n",
      "split file for D 1\n",
      "No data for symbol DPZ\n",
      "No data for symbol DOV\n",
      "No data for symbol DOW\n",
      "No data for symbol DTE\n",
      "split file for DUK 3\n",
      "No data for symbol DRE\n",
      "split file for DD 1\n",
      "split file for DXC 1\n",
      "split file for ETFC 3\n",
      "split file for EMN 1\n",
      "split file for ETN 3\n",
      "split file for EBAY 4\n",
      "split file for ECL 2\n",
      "No data for symbol EIX\n",
      "split file for EW 3\n",
      "split file for EA 2\n",
      "split file for EMR 1\n",
      "No data for symbol ETR\n",
      "split file for EOG 2\n",
      "No data for symbol EFX\n",
      "split file for EQIX 1\n",
      "split file for EQR 1\n",
      "No data for symbol ESS\n",
      "split file for EL 2\n",
      "No data for symbol RE\n",
      "No data for symbol EVRG\n",
      "split file for ES 1\n",
      "split file for EXC 1\n",
      "split file for EXPE 1\n",
      "split file for EXPD 3\n",
      "No data for symbol EXR\n",
      "split file for XOM 1\n",
      "split file for FFIV 1\n",
      "No data for symbol FB\n",
      "split file for FAST 4\n",
      "No data for symbol FRT\n",
      "split file for FDX 1\n",
      "No data for symbol FIS\n",
      "split file for FITB 2\n",
      "No data for symbol FRC\n",
      "split file for FE 1\n",
      "split file for FISV 5\n",
      "No data for symbol FLT\n",
      "split file for FLIR 3\n",
      "split file for FLS 1\n",
      "split file for FMC 2\n",
      "split file for F 3\n",
      "split file for FTNT 1\n",
      "split file for FTV 1\n",
      "No data for symbol FBHS\n",
      "No data for symbol FOXA\n",
      "No data for symbol FOX\n",
      "split file for BEN 2\n",
      "split file for FCX 1\n",
      "split file for GPS 2\n",
      "split file for GRMN 1\n",
      "No data for symbol IT\n",
      "split file for GD 2\n",
      "split file for GE 1\n",
      "split file for GIS 2\n",
      "No data for symbol GM\n",
      "No data for symbol GPC\n",
      "split file for GILD 5\n",
      "split file for GPN 2\n",
      "split file for GL 2\n",
      "No data for symbol GS\n",
      "split file for GWW 1\n",
      "split file for HRB 2\n",
      "split file for HAL 1\n",
      "split file for HBI 1\n",
      "split file for HIG 1\n",
      "split file for HAS 1\n",
      "No data for symbol HCA\n",
      "split file for PEAK 1\n",
      "split file for HSIC 2\n",
      "split file for HES 1\n",
      "No data for symbol HPE\n",
      "split file for HLT 2\n",
      "split file for HFC 4\n",
      "split file for HOLX 2\n",
      "split file for HD 2\n",
      "No data for symbol HON\n",
      "split file for HRL 3\n",
      "split file for HST 1\n",
      "No data for symbol HWM\n",
      "split file for HPQ 1\n",
      "No data for symbol HUM\n",
      "split file for HBAN 3\n",
      "No data for symbol HII\n",
      "split file for IEX 2\n",
      "split file for IDXX 2\n",
      "No data for symbol INFO\n",
      "split file for ITW 1\n",
      "split file for ILMN 1\n",
      "split file for INCY 1\n",
      "split file for IR 2\n",
      "split file for INTC 2\n",
      "split file for ICE 1\n",
      "split file for IBM 1\n",
      "No data for symbol IFF\n",
      "No data for symbol IP\n",
      "split file for IPG 1\n",
      "split file for INTU 2\n",
      "split file for ISRG 2\n",
      "split file for IVZ 3\n",
      "No data for symbol IPGP\n",
      "No data for symbol IQV\n",
      "split file for IRM 4\n",
      "split file for JBHT 2\n",
      "split file for JKHY 2\n",
      "split file for J 2\n",
      "split file for SJM 1\n",
      "split file for JNJ 1\n",
      "split file for JCI 5\n",
      "split file for JPM 2\n",
      "split file for JNPR 2\n",
      "split file for KSU 1\n",
      "No data for symbol K\n",
      "split file for KEY 1\n",
      "No data for symbol KEYS\n",
      "No data for symbol KMB\n",
      "split file for KIM 2\n",
      "No data for symbol KMI\n",
      "split file for KLAC 1\n",
      "split file for KSS 2\n",
      "No data for symbol KHC\n",
      "split file for KR 2\n",
      "split file for LB 2\n",
      "split file for LHX 2\n",
      "split file for LH 3\n",
      "split file for LRCX 1\n",
      "No data for symbol LW\n",
      "No data for symbol LVS\n",
      "split file for LEG 1\n",
      "split file for LDOS 1\n",
      "split file for LEN 1\n",
      "No data for symbol LLY\n",
      "split file for LNC 1\n",
      "split file for LIN 1\n",
      "No data for symbol LYV\n",
      "split file for LKQ 3\n",
      "split file for LMT 1\n",
      "split file for L 2\n",
      "split file for LOW 3\n",
      "No data for symbol LYB\n",
      "split file for MTB 1\n",
      "split file for MRO 2\n",
      "split file for MPC 1\n",
      "No data for symbol MKTX\n",
      "split file for MAR 5\n",
      "split file for MMC 2\n",
      "No data for symbol MLM\n",
      "split file for MAS 1\n",
      "split file for MA 1\n",
      "split file for MXIM 1\n",
      "split file for MKC 2\n",
      "split file for MCD 1\n",
      "split file for MCK 1\n",
      "split file for MDT 1\n",
      "split file for MRK 1\n",
      "No data for symbol MET\n",
      "No data for symbol MTD\n",
      "split file for MGM 2\n",
      "split file for MCHP 3\n",
      "split file for MU 1\n",
      "split file for MSFT 3\n",
      "No data for symbol MAA\n",
      "No data for symbol MHK\n",
      "split file for TAP 1\n",
      "No data for symbol MDLZ\n",
      "split file for MNST 4\n",
      "split file for MCO 1\n",
      "split file for MS 1\n",
      "split file for MSI 3\n",
      "No data for symbol MSCI\n",
      "split file for MYL 2\n",
      "No data for symbol NDAQ\n",
      "split file for NOV 1\n",
      "split file for NTAP 3\n",
      "split file for NFLX 2\n",
      "No data for symbol NWL\n",
      "No data for symbol NEM\n",
      "No data for symbol NWSA\n",
      "No data for symbol NWS\n",
      "split file for NEE 2\n",
      "No data for symbol NLSN\n",
      "split file for NKE 3\n",
      "split file for NI 1\n",
      "split file for NBL 2\n",
      "No data for symbol NSC\n",
      "split file for NTRS 1\n",
      "split file for NOC 2\n",
      "No data for symbol NLOK\n",
      "No data for symbol NCLH\n",
      "split file for NRG 1\n",
      "split file for NUE 2\n",
      "split file for NVDA 4\n",
      "No data for symbol NVR\n",
      "split file for ORLY 2\n",
      "split file for OXY 1\n",
      "split file for ODFL 6\n",
      "split file for OMC 1\n",
      "split file for OKE 2\n",
      "split file for ORCL 3\n",
      "No data for symbol OTIS\n",
      "split file for PCAR 4\n",
      "No data for symbol PKG\n",
      "split file for PH 1\n",
      "split file for PAYX 3\n",
      "No data for symbol PAYC\n",
      "No data for symbol PYPL\n",
      "split file for PNR 1\n",
      "split file for PBCT 3\n",
      "No data for symbol PEP\n",
      "split file for PKI 1\n",
      "No data for symbol PRGO\n",
      "split file for PFE 1\n",
      "No data for symbol PM\n",
      "No data for symbol PSX\n",
      "split file for PNW 1\n",
      "No data for symbol PXD\n",
      "No data for symbol PNC\n",
      "split file for PPG 1\n",
      "split file for PPL 1\n",
      "No data for symbol PFG\n",
      "split file for PG 1\n",
      "split file for PGR 2\n",
      "No data for symbol PLD\n",
      "No data for symbol PRU\n",
      "split file for PEG 1\n",
      "No data for symbol PSA\n",
      "split file for PHM 3\n",
      "No data for symbol PVH\n",
      "No data for symbol QRVO\n",
      "split file for QCOM 3\n",
      "split file for PWR 1\n",
      "split file for DGX 2\n",
      "No data for symbol RL\n",
      "split file for RJF 3\n",
      "No data for symbol RTX\n",
      "split file for O 1\n",
      "No data for symbol REG\n",
      "No data for symbol REGN\n",
      "split file for RF 1\n",
      "split file for RSG 1\n",
      "split file for RMD 4\n",
      "split file for RHI 1\n",
      "No data for symbol ROK\n",
      "split file for ROL 7\n",
      "split file for ROP 1\n",
      "split file for ROST 4\n",
      "split file for RCL 1\n",
      "split file for SPGI 2\n",
      "split file for CRM 1\n",
      "No data for symbol SBAC\n",
      "split file for SLB 1\n",
      "No data for symbol STX\n",
      "split file for SEE 1\n",
      "No data for symbol SRE\n",
      "No data for symbol NOW\n",
      "No data for symbol SHW\n",
      "split file for SPG 2\n",
      "split file for SWKS 2\n",
      "split file for SLG 1\n",
      "No data for symbol SNA\n",
      "split file for SO 1\n",
      "split file for LUV 3\n",
      "No data for symbol SWK\n",
      "split file for SBUX 4\n",
      "split file for STT 1\n",
      "split file for STE 1\n",
      "split file for SYK 2\n",
      "split file for SIVB 2\n",
      "No data for symbol SYF\n",
      "split file for SNPS 1\n",
      "split file for SYY 2\n",
      "split file for TMUS 1\n",
      "split file for TROW 2\n",
      "split file for TTWO 1\n",
      "split file for TPR 3\n",
      "split file for TGT 2\n",
      "No data for symbol TEL\n",
      "split file for FTI 2\n",
      "No data for symbol TDY\n",
      "No data for symbol TFX\n",
      "split file for TXN 2\n",
      "split file for TXT 1\n",
      "split file for BK 2\n",
      "split file for CLX 1\n",
      "split file for COO 1\n",
      "split file for HSY 1\n",
      "No data for symbol MOS\n",
      "split file for TRV 1\n",
      "split file for DIS 2\n",
      "No data for symbol TMO\n",
      "split file for TIF 2\n",
      "split file for TJX 4\n",
      "split file for TSCO 4\n",
      "No data for symbol TT\n",
      "No data for symbol TDG\n",
      "split file for TFC 1\n",
      "No data for symbol TWTR\n",
      "No data for symbol TYL\n",
      "No data for symbol TSN\n",
      "split file for USB 3\n",
      "No data for symbol UDR\n",
      "No data for symbol ULTA\n",
      "split file for UAA 1\n",
      "split file for UA 2\n",
      "split file for UNP 2\n",
      "No data for symbol UAL\n",
      "split file for UNH 3\n",
      "No data for symbol UPS\n",
      "No data for symbol URI\n",
      "split file for UHS 2\n",
      "No data for symbol UNM\n",
      "split file for VLO 3\n",
      "split file for VAR 3\n",
      "No data for symbol VTR\n",
      "split file for VRSN 2\n",
      "No data for symbol VRSK\n",
      "split file for VZ 4\n",
      "split file for VRTX 1\n",
      "split file for VFC 1\n",
      "No data for symbol VIAC\n",
      "split file for V 1\n",
      "split file for VNO 1\n",
      "split file for VMC 1\n",
      "split file for WRB 5\n",
      "split file for WAB 1\n",
      "split file for WBA 1\n",
      "split file for WMT 1\n",
      "No data for symbol WM\n",
      "split file for WAT 2\n",
      "split file for WEC 1\n",
      "split file for WFC 1\n",
      "No data for symbol WELL\n",
      "split file for WST 2\n",
      "No data for symbol WDC\n",
      "No data for symbol WU\n",
      "No data for symbol WRK\n",
      "split file for WY 1\n",
      "No data for symbol WHR\n",
      "split file for WMB 2\n",
      "No data for symbol WLTW\n",
      "No data for symbol WYNN\n",
      "split file for XEL 1\n",
      "split file for XRX 2\n",
      "split file for XLNX 2\n",
      "No data for symbol XYL\n",
      "split file for YUM 2\n",
      "split file for ZBRA 2\n",
      "No data for symbol ZBH\n",
      "No data for symbol ZION\n",
      "No data for symbol ZTS\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'332 file were exported'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#%%  Pull in all the stock splits\n",
    "get_splits(symbols, 'data/splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MA\n",
      "         date ticker  ratio  tofactor  forfactor\n",
      "0  2014-01-21     MA    0.1         1         10\n",
      "           ticker  ratio\n",
      "date                    \n",
      "2014-01-22     MA    0.1\n",
      "Split file for MA corrected\n",
      "NFLX\n",
      "         date ticker splitDeclaredDate     ratio  tofactor  forfactor\n",
      "0  2015-07-14   NFLX        2015-06-23  0.142857       1.0        7.0\n",
      "1  2004-02-12   NFLX               NaN  0.500000       NaN        NaN\n",
      "           ticker  ratio\n",
      "date                    \n",
      "2015-07-15   NFLX  0.143\n",
      "2004-02-12   NFLX  0.500\n",
      "Split file for NFLX corrected\n",
      "BRK.A\n",
      "no file found\n",
      "EWZ\n",
      "no file found\n",
      "JEF\n",
      "no file found\n",
      "WY\n",
      "         date ticker  ratio\n",
      "0  2010-07-19     WY    0.5\n",
      "           ticker  ratio\n",
      "date                    \n",
      "2010-07-20     WY    0.5\n",
      "Split file for WY corrected\n",
      "STN\n",
      "no file found\n",
      "CTSH\n",
      "         date ticker splitDeclaredDate     ratio  tofactor  forfactor\n",
      "0  2014-03-06   CTSH        2014-02-04  0.500000       1.0        2.0\n",
      "1  2007-10-17   CTSH               NaN  0.500000       NaN        NaN\n",
      "2  2004-06-18   CTSH               NaN  0.500000       NaN        NaN\n",
      "3  2003-04-02   CTSH               NaN  0.333333       NaN        NaN\n",
      "4  2000-03-17   CTSH               NaN  0.500000       NaN        NaN\n",
      "           ticker     ratio\n",
      "date                       \n",
      "2014-03-10   CTSH  0.500000\n",
      "2007-10-17   CTSH  0.500000\n",
      "2004-06-18   CTSH  0.500000\n",
      "2003-04-02   CTSH  0.333333\n",
      "2000-03-17   CTSH  0.500000\n",
      "Split file for CTSH corrected\n",
      "ENB\n",
      "no file found\n",
      "TQQQ\n",
      "no file found\n",
      "MNST\n",
      "         date ticker splitDeclaredDate     ratio  tofactor  forfactor\n",
      "0  2016-11-10   MNST        2016-10-14  0.333333       1.0        3.0\n",
      "1  2012-02-16   MNST               NaN  0.500000       NaN        NaN\n",
      "2  2006-07-10   MNST               NaN  0.250000       NaN        NaN\n",
      "3  2005-08-09   MNST               NaN  0.500000       NaN        NaN\n",
      "           ticker     ratio\n",
      "date                       \n",
      "2016-11-10   MNST  0.333333\n",
      "2012-02-16   MNST  0.500000\n",
      "2006-07-10   MNST  1.000000\n",
      "2005-08-09   MNST  1.000000\n",
      "Split file for MNST corrected\n",
      "CNC\n",
      "         date ticker     ratio  tofactor  forfactor splitDeclaredDate\n",
      "0  2019-02-07    CNC  0.500000       1.0        2.0               NaN\n",
      "1  2015-02-18    CNC  0.500000       1.0        2.0        2015-02-03\n",
      "2  2004-12-20    CNC  0.500000       NaN        NaN               NaN\n",
      "3  2003-07-14    CNC  0.666667       NaN        NaN               NaN\n",
      "           ticker     ratio\n",
      "date                       \n",
      "2019-02-07    CNC  0.500000\n",
      "2015-02-20    CNC  0.500000\n",
      "2004-12-20    CNC  0.500000\n",
      "2003-07-14    CNC  0.666667\n",
      "Split file for CNC corrected\n",
      "CHD\n",
      "         date ticker     ratio  tofactor  forfactor\n",
      "0  2016-08-31    CHD  0.500000       1.0        2.0\n",
      "1  2011-06-02    CHD  0.500000       NaN        NaN\n",
      "2  2004-09-02    CHD  0.666667       NaN        NaN\n",
      "3  1999-09-02    CHD  0.500000       NaN        NaN\n",
      "           ticker     ratio\n",
      "date                       \n",
      "2016-09-02    CHD  0.500000\n",
      "2011-06-02    CHD  0.500000\n",
      "2004-09-02    CHD  0.666667\n",
      "1999-09-02    CHD  0.500000\n",
      "Split file for CHD corrected\n",
      "SPR\n",
      "no file found\n",
      "ERIC\n",
      "no file found\n",
      "PDS\n",
      "no file found\n",
      "CLR\n",
      "no file found\n",
      "GEN\n",
      "no file found\n",
      "NUGT\n",
      "no file found\n",
      "ODP\n",
      "no file found\n",
      "ITT\n",
      "no file found\n",
      "ADS\n",
      "no file found\n",
      "TZA\n",
      "no file found\n",
      "FAZ\n",
      "no file found\n",
      "VXX\n",
      "no file found\n",
      "MRO\n",
      "         date ticker   ratio\n",
      "0  2011-06-30    MRO  0.5965\n",
      "1  2007-06-19    MRO  0.5000\n",
      "           ticker  ratio\n",
      "date                    \n",
      "2011-07-01    MRO  0.597\n",
      "2007-06-19    MRO  0.500\n",
      "Split file for MRO corrected\n",
      "JNK\n",
      "no file found\n",
      "HLT\n",
      "         date ticker splitDeclaredDate  ratio  tofactor  forfactor\n",
      "0  2017-01-04    HLT        2017-01-04      3         3          1\n",
      "1  2017-01-03    HLT        2017-01-03      3         3          1\n",
      "           ticker  ratio\n",
      "date                    \n",
      "2017-01-04    HLT    3.0\n",
      "2017-01-03    HLT    1.0\n",
      "Split file for HLT corrected\n",
      "CAL\n",
      "no file found\n",
      "CTXS\n",
      "         date ticker     ratio  tofactor  forfactor\n",
      "0  2017-02-01   CTXS  0.500000       1.0        2.0\n",
      "1  2000-02-17   CTXS  0.500000       NaN        NaN\n",
      "2  1999-03-26   CTXS  0.500000       NaN        NaN\n",
      "3  1998-02-23   CTXS  0.666667       NaN        NaN\n",
      "           ticker     ratio\n",
      "date                       \n",
      "2017-02-01   CTXS  0.840000\n",
      "2000-02-17   CTXS  0.500000\n",
      "1999-03-26   CTXS  0.500000\n",
      "1998-02-23   CTXS  0.666667\n",
      "Split file for CTXS corrected\n",
      "GOOG\n",
      "         date ticker splitDeclaredDate  ratio  tofactor  forfactor\n",
      "0  2015-04-27   GOOG        2015-04-27      1  10000000   10027455\n",
      "1  2014-03-27   GOOG        2014-03-27      2      1000       2002\n",
      "           ticker  ratio\n",
      "date                    \n",
      "2015-04-27   GOOG    1.0\n",
      "2014-04-03   GOOG    2.0\n",
      "Split file for GOOG corrected\n",
      "CPA\n",
      "no file found\n",
      "EXPE\n",
      "         date ticker  ratio\n",
      "0  2011-12-22   EXPE      2\n",
      "           ticker  ratio\n",
      "date                    \n",
      "2011-12-22   EXPE    1.0\n",
      "Split file for EXPE corrected\n",
      "nan\n",
      "no file found\n",
      "div file for MMM 29\n",
      "div file for AOS 29\n",
      "div file for ABT 30\n",
      "div file for ABBV 30\n",
      "div file for ACN 19\n",
      "div file for ATVI 11\n",
      "div file for ADBE 66\n",
      "div file for AAP 29\n",
      "div file for AES 31\n",
      "div file for AFL 30\n",
      "div file for A 30\n",
      "div file for APD 30\n",
      "div file for ALK 28\n",
      "div file for ALB 29\n",
      "div file for ARE 30\n",
      "div file for ALLE 28\n",
      "div file for LNT 80\n",
      "div file for ALL 29\n",
      "div file for MO 29\n",
      "div file for AMCR 5\n",
      "div file for AEE 30\n",
      "div file for AAL 23\n",
      "div file for AEP 29\n",
      "div file for AXP 29\n",
      "div file for AIG 29\n",
      "div file for AMT 30\n",
      "div file for AWK 30\n",
      "div file for AMP 29\n",
      "div file for ABC 30\n",
      "div file for AME 30\n",
      "div file for AMGN 38\n",
      "div file for APH 29\n",
      "div file for ADI 67\n",
      "div file for ANTM 24\n",
      "div file for AON 32\n",
      "div file for APA 27\n",
      "div file for AIV 31\n",
      "div file for AAPL 62\n",
      "div file for AMAT 62\n",
      "div file for APTV 10\n",
      "div file for ADM 29\n",
      "div file for AJG 29\n",
      "div file for AIZ 30\n",
      "div file for T 31\n",
      "div file for ATO 30\n",
      "div file for ADSK 63\n",
      "div file for ADP 78\n",
      "div file for AVB 30\n",
      "div file for AVY 29\n",
      "div file for BKR 5\n",
      "div file for BLL 29\n",
      "div file for BAC 29\n",
      "div file for BAX 29\n",
      "div file for BDX 29\n",
      "div file for BBY 30\n",
      "div file for BLK 30\n",
      "div file for BA 27\n",
      "div file for BWA 29\n",
      "div file for BXP 29\n",
      "div file for BMY 29\n",
      "div file for AVGO 40\n",
      "div file for BR 29\n",
      "div file for BF.B 29\n",
      "div file for CHRW 93\n",
      "div file for COG 29\n",
      "div file for CPB 30\n",
      "div file for COF 29\n",
      "div file for CAH 28\n",
      "div file for CCL 26\n",
      "div file for CARR 3\n",
      "div file for CAT 31\n",
      "div file for CBOE 36\n",
      "div file for CDW 29\n",
      "div file for CE 30\n",
      "div file for CNP 29\n",
      "div file for CTL 29\n",
      "div file for CERN 6\n",
      "div file for CF 30\n",
      "div file for SCHW 30\n",
      "div file for CVX 30\n",
      "div file for CB 31\n",
      "div file for CHD 30\n",
      "div file for CI 8\n",
      "div file for CINF 131\n",
      "div file for CTAS 33\n",
      "div file for CSCO 38\n",
      "div file for C 29\n",
      "div file for CFG 24\n",
      "div file for CTXS 8\n",
      "div file for CME 80\n",
      "div file for CMS 30\n",
      "div file for KO 29\n",
      "div file for CTSH 14\n",
      "div file for CL 31\n",
      "div file for CMCSA 92\n",
      "div file for CMA 29\n",
      "div file for CAG 30\n",
      "div file for CXO 8\n",
      "div file for COP 29\n",
      "div file for ED 30\n",
      "div file for STZ 23\n",
      "div file for GLW 29\n",
      "div file for CTVA 5\n",
      "div file for COST 71\n",
      "div file for COTY 18\n",
      "div file for CCI 27\n",
      "div file for CSX 81\n",
      "div file for CMI 29\n",
      "div file for CVS 31\n",
      "div file for DHI 29\n",
      "div file for DHR 31\n",
      "div file for DRI 26\n",
      "div file for DE 30\n",
      "div file for DAL 27\n",
      "div file for XRAY 105\n",
      "div file for DVN 31\n",
      "div file for FANG 10\n",
      "div file for DLR 29\n",
      "div file for DFS 29\n",
      "div file for DISH 4\n",
      "div file for DG 23\n",
      "div file for D 29\n",
      "div file for DPZ 29\n",
      "div file for DOV 29\n",
      "div file for DOW 24\n",
      "div file for DTE 29\n",
      "div file for DUK 30\n",
      "div file for DRE 30\n",
      "div file for DD 7\n",
      "div file for DXC 13\n",
      "div file for ETFC 7\n",
      "div file for EMN 29\n",
      "div file for ETN 31\n",
      "div file for EBAY 7\n",
      "div file for ECL 29\n",
      "div file for EIX 30\n",
      "div file for EA 1\n",
      "div file for EMR 30\n",
      "div file for ETR 29\n",
      "div file for EOG 30\n",
      "div file for EFX 30\n",
      "div file for EQIX 26\n",
      "div file for EQR 29\n",
      "div file for ESS 29\n",
      "div file for EL 28\n",
      "div file for RE 29\n",
      "div file for EVRG 10\n",
      "div file for ES 23\n",
      "div file for EXC 30\n",
      "div file for EXPE 43\n",
      "div file for EXPD 56\n",
      "div file for EXR 30\n",
      "div file for XOM 30\n",
      "div file for FAST 72\n",
      "div file for FRT 28\n",
      "div file for FDX 29\n",
      "div file for FIS 29\n",
      "div file for FITB 128\n",
      "div file for FRC 31\n",
      "div file for FE 30\n",
      "div file for FLIR 39\n",
      "div file for FLS 31\n",
      "div file for FMC 29\n",
      "div file for F 27\n",
      "div file for FTV 18\n",
      "div file for FBHS 29\n",
      "div file for FOXA 4\n",
      "div file for FOX 4\n",
      "div file for BEN 29\n",
      "div file for FCX 18\n",
      "div file for GPS 29\n",
      "div file for GRMN 46\n",
      "div file for GD 30\n",
      "div file for GE 30\n",
      "div file for GIS 30\n",
      "div file for GM 25\n",
      "div file for GPC 30\n",
      "div file for GILD 22\n",
      "div file for GPN 29\n",
      "div file for GL 5\n",
      "div file for GS 29\n",
      "div file for GWW 29\n",
      "div file for HRB 30\n",
      "div file for HAL 29\n",
      "div file for HBI 30\n",
      "div file for HIG 29\n",
      "div file for HAS 83\n",
      "div file for HCA 10\n",
      "div file for PEAK 5\n",
      "div file for HES 30\n",
      "div file for HPE 20\n",
      "div file for HLT 19\n",
      "div file for HFC 29\n",
      "div file for HD 30\n",
      "div file for HON 31\n",
      "div file for HRL 30\n",
      "div file for HST 28\n",
      "div file for HWM 2\n",
      "div file for HPQ 29\n",
      "div file for HUM 28\n",
      "div file for HBAN 127\n",
      "div file for HII 29\n",
      "div file for IEX 30\n",
      "div file for ITW 29\n",
      "div file for IR 27\n",
      "div file for INTC 113\n",
      "div file for ICE 30\n",
      "div file for IBM 29\n",
      "div file for IFF 29\n",
      "div file for IP 30\n",
      "div file for IPG 29\n",
      "div file for INTU 38\n",
      "div file for IVZ 31\n",
      "div file for IPGP 1\n",
      "div file for IRM 31\n",
      "div file for JBHT 113\n",
      "div file for JKHY 121\n",
      "div file for J 5\n",
      "div file for SJM 30\n",
      "div file for JNJ 29\n",
      "div file for JCI 29\n",
      "div file for JPM 30\n",
      "div file for JNPR 25\n",
      "div file for KSU 30\n",
      "div file for K 29\n",
      "div file for KEY 29\n",
      "div file for KMB 29\n",
      "div file for KIM 28\n",
      "div file for KMI 28\n",
      "div file for KLAC 64\n",
      "div file for KSS 27\n",
      "div file for KHC 22\n",
      "div file for KR 31\n",
      "div file for LB 26\n",
      "div file for LHX 5\n",
      "div file for LRCX 26\n",
      "div file for LW 16\n",
      "div file for LVS 27\n",
      "div file for LEG 29\n",
      "div file for LDOS 30\n",
      "div file for LEN 30\n",
      "div file for LLY 30\n",
      "div file for LNC 30\n",
      "div file for LIN 3\n",
      "div file for LMT 30\n",
      "div file for L 30\n",
      "div file for LOW 31\n",
      "div file for LYB 31\n",
      "div file for MTB 30\n",
      "div file for MRO 28\n",
      "div file for MPC 30\n",
      "div file for MKTX 45\n",
      "div file for MAR 76\n",
      "div file for MMC 30\n",
      "div file for MLM 30\n",
      "div file for MAS 30\n",
      "div file for MA 30\n",
      "div file for MXIM 71\n",
      "div file for MKC 31\n",
      "div file for MCD 29\n",
      "div file for MCK 29\n",
      "div file for MDT 30\n",
      "div file for MRK 29\n",
      "div file for MET 30\n",
      "div file for MGM 15\n",
      "div file for MCHP 72\n",
      "div file for MSFT 67\n",
      "div file for MAA 30\n",
      "div file for TAP 27\n",
      "div file for MDLZ 76\n",
      "div file for MCO 29\n",
      "div file for MS 29\n",
      "div file for MSI 29\n",
      "div file for MSCI 25\n",
      "div file for MYL 28\n",
      "div file for NDAQ 34\n",
      "div file for NOV 27\n",
      "div file for NTAP 29\n",
      "div file for NWL 81\n",
      "div file for NEM 30\n",
      "div file for NWSA 11\n",
      "div file for NWS 11\n",
      "div file for NEE 29\n",
      "div file for NLSN 29\n",
      "div file for NKE 29\n",
      "div file for NI 28\n",
      "div file for NBL 28\n",
      "div file for NSC 30\n",
      "div file for NTRS 128\n",
      "div file for NOC 30\n",
      "div file for NLOK 6\n",
      "div file for NRG 30\n",
      "div file for NUE 30\n",
      "div file for NVDA 32\n",
      "div file for OXY 29\n",
      "div file for ODFL 15\n",
      "div file for OMC 29\n",
      "div file for OKE 29\n",
      "div file for ORCL 30\n",
      "div file for OTIS 2\n",
      "div file for PCAR 161\n",
      "div file for PKG 30\n",
      "div file for PH 29\n",
      "div file for PAYX 128\n",
      "div file for PNR 32\n",
      "div file for PBCT 118\n",
      "div file for PEP 81\n",
      "div file for PKI 29\n",
      "div file for PRGO 29\n",
      "div file for PFE 31\n",
      "div file for PM 30\n",
      "div file for PSX 29\n",
      "div file for PNW 31\n",
      "div file for PXD 18\n",
      "div file for PNC 29\n",
      "div file for PPG 29\n",
      "div file for PPL 30\n",
      "div file for PFG 46\n",
      "div file for PG 31\n",
      "div file for PGR 14\n",
      "div file for PLD 30\n",
      "div file for PRU 29\n",
      "div file for PEG 29\n",
      "div file for PSA 29\n",
      "div file for PHM 30\n",
      "div file for PVH 27\n",
      "div file for QCOM 71\n",
      "div file for PWR 7\n",
      "div file for DGX 31\n",
      "div file for RL 28\n",
      "div file for RJF 29\n",
      "div file for RTX 4\n",
      "div file for O 88\n",
      "div file for REG 82\n",
      "div file for RF 29\n",
      "div file for RSG 30\n",
      "div file for RMD 30\n",
      "div file for RHI 30\n",
      "div file for ROK 30\n",
      "div file for ROL 29\n",
      "div file for ROP 30\n",
      "div file for ROST 105\n",
      "div file for RCL 28\n",
      "div file for SPGI 20\n",
      "div file for SBAC 5\n",
      "div file for SLB 29\n",
      "div file for STX 63\n",
      "div file for SEE 29\n",
      "div file for SRE 30\n",
      "div file for SHW 30\n",
      "div file for SPG 29\n",
      "div file for SWKS 26\n",
      "div file for SLG 35\n",
      "div file for SNA 29\n",
      "div file for SO 30\n",
      "div file for LUV 27\n",
      "div file for SWK 29\n",
      "div file for SBUX 43\n",
      "div file for STT 28\n",
      "div file for STE 28\n",
      "div file for SYK 29\n",
      "div file for SIVB 6\n",
      "div file for SYF 17\n",
      "div file for SYY 29\n",
      "div file for TMUS 1\n",
      "div file for TROW 129\n",
      "div file for TTWO 1\n",
      "div file for TPR 11\n",
      "div file for TGT 30\n",
      "div file for TEL 29\n",
      "div file for FTI 2\n",
      "div file for TFX 31\n",
      "div file for TXN 81\n",
      "div file for TXT 29\n",
      "div file for BK 30\n",
      "div file for CLX 30\n",
      "div file for COO 16\n",
      "div file for HSY 29\n",
      "div file for MOS 29\n",
      "div file for TRV 29\n",
      "div file for DIS 13\n",
      "div file for TMO 29\n",
      "div file for TIF 29\n",
      "div file for TJX 27\n",
      "div file for TSCO 43\n",
      "div file for TT 3\n",
      "div file for TFC 5\n",
      "div file for TSN 29\n",
      "div file for USB 30\n",
      "div file for UDR 31\n",
      "div file for ULTA 1\n",
      "div file for UNP 29\n",
      "div file for UAL 1\n",
      "div file for UNH 30\n",
      "div file for UPS 30\n",
      "div file for UHS 27\n",
      "div file for UNM 30\n",
      "div file for VLO 30\n",
      "div file for VTR 30\n",
      "div file for VRSN 2\n",
      "div file for VRSK 7\n",
      "div file for VZ 24\n",
      "div file for VFC 30\n",
      "div file for VIAC 3\n",
      "div file for V 30\n",
      "div file for VNO 30\n",
      "div file for VMC 30\n",
      "div file for WRB 29\n",
      "div file for WAB 30\n",
      "div file for WBA 81\n",
      "div file for WMT 29\n",
      "div file for WM 30\n",
      "div file for WEC 30\n",
      "div file for WFC 30\n",
      "div file for WELL 11\n",
      "div file for WST 30\n",
      "div file for WDC 30\n",
      "div file for WU 30\n",
      "div file for WRK 23\n",
      "div file for WY 28\n",
      "div file for WHR 29\n",
      "div file for WMB 30\n",
      "div file for WLTW 71\n",
      "div file for WYNN 44\n",
      "div file for XEL 81\n",
      "div file for XRX 29\n",
      "div file for XLNX 66\n",
      "div file for XYL 30\n",
      "div file for YUM 30\n",
      "div file for ZBH 21\n",
      "div file for ZION 127\n",
      "div file for ZTS 31\n",
      "CSCO\n",
      "UAL\n",
      "TROW\n",
      "ISRG\n",
      "NVR\n",
      "PRGO\n",
      "TPR\n",
      "DVN\n",
      "CE\n",
      "MRO\n",
      "BA\n",
      "VRTX\n",
      "BRK.B\n",
      "GILD\n",
      "NLSN\n",
      "EQIX\n",
      "TIF\n",
      "MDT\n",
      "V\n",
      "QRVO\n",
      "A\n",
      "FOX\n",
      "FLT\n",
      "MO\n",
      "SWKS\n",
      "MCHP\n",
      "CDNS\n",
      "WLTW\n",
      "MSCI\n",
      "CHTR\n",
      "EIX\n",
      "BBY\n",
      "WBA\n",
      "LVS\n",
      "HCA\n",
      "AJG\n",
      "DTE\n",
      "C\n",
      "T\n",
      "CF\n",
      "DISH\n",
      "MGM\n",
      "HUM\n",
      "CBOE\n",
      "CFG\n",
      "WU\n",
      "APH\n",
      "SYY\n",
      "MSI\n",
      "FCX\n",
      "ADM\n",
      "LH\n",
      "PKI\n",
      "LNT\n",
      "BAC\n",
      "LNC\n",
      "PSX\n",
      "GPN\n",
      "PPG\n",
      "IRM\n",
      "IQV\n",
      "ESS\n",
      "NOV\n",
      "HAL\n",
      "STZ\n",
      "FLS\n",
      "DXC\n",
      "ADI\n",
      "F\n",
      "ADBE\n",
      "CPRT\n",
      "TDG\n",
      "TFX\n",
      "ULTA\n",
      "ARE\n",
      "SYK\n",
      "CB\n",
      "TSN\n",
      "PEP\n",
      "PEG\n",
      "NOW\n",
      "LLY\n",
      "COST\n",
      "REG\n",
      "NWS\n",
      "LOW\n",
      "MDLZ\n",
      "BKNG\n",
      "ZBRA\n",
      "FMC\n",
      "XEL\n",
      "AIZ\n",
      "CERN\n",
      "MET\n",
      "FTV\n",
      "DLR\n",
      "XRAY\n",
      "FAST\n",
      "TJX\n",
      "SNA\n",
      "MPC\n",
      "BR\n",
      "D\n",
      "MRK\n",
      "STX\n",
      "NOC\n",
      "BXP\n",
      "KHC\n",
      "IPG\n",
      "UNP\n",
      "ALLE\n",
      "ABBV\n",
      "ORCL\n",
      "ECL\n",
      "ETR\n",
      "EBAY\n",
      "SBUX\n",
      "IR\n",
      "AMT\n",
      "INTU\n",
      "DPZ\n",
      "PAYC\n",
      "DRE\n",
      "CMA\n",
      "IPGP\n",
      "PG\n",
      "CAT\n",
      "ODFL\n",
      "MCD\n",
      "MNST\n",
      "AMZN\n",
      "INTC\n",
      "PNR\n",
      "GLW\n",
      "BDX\n",
      "KMI\n",
      "PWR\n",
      "APTV\n",
      "DXCM\n",
      "EXR\n",
      "WELL\n",
      "HOLX\n",
      "EXPD\n",
      "GM\n",
      "TXN\n",
      "VRSK\n",
      "SJM\n",
      "TMO\n",
      "OXY\n",
      "RL\n",
      "CCI\n",
      "MMM\n",
      "MOS\n",
      "FTNT\n",
      "HSY\n",
      "JNPR\n",
      "DHI\n",
      "ED\n",
      "ES\n",
      "ADSK\n",
      "GL\n",
      "IP\n",
      "EXPE\n",
      "KO\n",
      "PCAR\n",
      "WDC\n",
      "PYPL\n",
      "NEE\n",
      "UPS\n",
      "FLIR\n",
      "LEG\n",
      "EMR\n",
      "MSFT\n",
      "ANSS\n",
      "CTAS\n",
      "BIO\n",
      "UDR\n",
      "WEC\n",
      "AME\n",
      "IT\n",
      "DD\n",
      "ACN\n",
      "VRSN\n",
      "EW\n",
      "CMG\n",
      "AWK\n",
      "COO\n",
      "SHW\n",
      "HPQ\n",
      "AMAT\n",
      "CCL\n",
      "MLM\n",
      "AVY\n",
      "AAP\n",
      "ATVI\n",
      "EVRG\n",
      "EA\n",
      "DE\n",
      "SPG\n",
      "AMD\n",
      "MYL\n",
      "KLAC\n",
      "NDAQ\n",
      "URI\n",
      "WHR\n",
      "RTX\n",
      "PNC\n",
      "KMX\n",
      "WRK\n",
      "BIIB\n",
      "NVDA\n",
      "CHRW\n",
      "ROP\n",
      "IDXX\n",
      "EXC\n",
      "HES\n",
      "HD\n",
      "ALB\n",
      "VLO\n",
      "AON\n",
      "ZTS\n",
      "FDX\n",
      "DG\n",
      "TYL\n",
      "HIG\n",
      "CMS\n",
      "CAG\n",
      "INCY\n",
      "SCHW\n",
      "HSIC\n",
      "AZO\n",
      "AXP\n",
      "HPE\n",
      "DFS\n",
      "SEE\n",
      "HRL\n",
      "SO\n",
      "FRT\n",
      "ZBH\n",
      "FRC\n",
      "CME\n",
      "XOM\n",
      "AMP\n",
      "BF.B\n",
      "CVX\n",
      "ETFC\n",
      "CMCSA\n",
      "PNW\n",
      "ICE\n",
      "CTXS\n",
      "BEN\n",
      "DISCK\n",
      "UHS\n",
      "BKR\n",
      "EMN\n",
      "SBAC\n",
      "ROK\n",
      "NRG\n",
      "NSC\n",
      "NKE\n",
      "FIS\n",
      "FANG\n",
      "VTR\n",
      "MAS\n",
      "RF\n",
      "AMCR\n",
      "TAP\n",
      "MAR\n",
      "XYL\n",
      "CMI\n",
      "FB\n",
      "MTD\n",
      "VAR\n",
      "NLOK\n",
      "KR\n",
      "PLD\n",
      "IBM\n",
      "USB\n",
      "BSX\n",
      "LKQ\n",
      "FBHS\n",
      "LIN\n",
      "ITW\n",
      "TWTR\n",
      "EOG\n",
      "PVH\n",
      "KMB\n",
      "PEAK\n",
      "SPGI\n",
      "NEM\n",
      "WFC\n",
      "CTVA\n",
      "EL\n",
      "GS\n",
      "GD\n",
      "CNP\n",
      "PM\n",
      "RE\n",
      "MCO\n",
      "CLX\n",
      "CAH\n",
      "HRB\n",
      "DGX\n",
      "AVB\n",
      "DIS\n",
      "CBRE\n",
      "GE\n",
      "HII\n",
      "LDOS\n",
      "ALL\n",
      "ETN\n",
      "ALGN\n",
      "NFLX\n",
      "LEN\n",
      "FITB\n",
      "WST\n",
      "GWW\n",
      "NTRS\n",
      "CVS\n",
      "CTL\n",
      "AOS\n",
      "FE\n",
      "ABC\n",
      "JPM\n",
      "ABT\n",
      "CXO\n",
      "OMC\n",
      "COF\n",
      "TSCO\n",
      "PH\n",
      "HST\n",
      "JBHT\n",
      "ATO\n",
      "COP\n",
      "DHR\n",
      "COG\n",
      "CNC\n",
      "MCK\n",
      "TXT\n",
      "MTB\n",
      "HFC\n",
      "DISCA\n",
      "AKAM\n",
      "ROL\n",
      "RMD\n",
      "WRB\n",
      "GOOGL\n",
      "ANET\n",
      "PAYX\n",
      "ALK\n",
      "DRI\n",
      "ILMN\n",
      "AAL\n",
      "XLNX\n",
      "MAA\n",
      "MMC\n",
      "FOXA\n",
      "FFIV\n",
      "VNO\n",
      "CINF\n",
      "VMC\n",
      "MKTX\n",
      "SRE\n",
      "LHX\n",
      "ORLY\n",
      "IVZ\n",
      "RCL\n",
      "PXD\n",
      "COTY\n",
      "SNPS\n",
      "GOOG\n",
      "SIVB\n",
      "YUM\n",
      "LYV\n",
      "KSS\n",
      "PFE\n",
      "AIV\n",
      "AVGO\n",
      "DUK\n",
      "REGN\n",
      "CL\n",
      "VFC\n",
      "UA\n",
      "VZ\n",
      "JCI\n",
      "AMGN\n",
      "TEL\n",
      "JKHY\n",
      "ADP\n",
      "LB\n",
      "STT\n",
      "RSG\n",
      "IFF\n",
      "ANTM\n",
      "GPS\n",
      "BLL\n",
      "CARR\n",
      "QCOM\n",
      "LYB\n",
      "GIS\n",
      "PHM\n",
      "ROST\n",
      "LUV\n",
      "ALXN\n",
      "LW\n",
      "MS\n",
      "CPB\n",
      "OKE\n",
      "BK\n",
      "J\n",
      "SYF\n",
      "CHD\n",
      "SLG\n",
      "HWM\n",
      "MHK\n",
      "TFC\n",
      "INFO\n",
      "DAL\n",
      "APA\n",
      "K\n",
      "AFL\n",
      "CSX\n",
      "NI\n",
      "PFG\n",
      "NCLH\n",
      "ZION\n",
      "RJF\n",
      "HBAN\n",
      "UNH\n",
      "PRU\n",
      "GPC\n",
      "FISV\n",
      "WMB\n",
      "EQR\n",
      "MXIM\n",
      "PBCT\n",
      "KSU\n",
      "DVA\n",
      "AIG\n",
      "MA\n",
      "HBI\n",
      "HON\n",
      "O\n",
      "NWSA\n",
      "TTWO\n",
      "AES\n",
      "SLB\n",
      "TT\n",
      "XRX\n",
      "TGT\n",
      "AAPL\n",
      "MKC\n",
      "OTIS\n",
      "TDY\n",
      "WY\n",
      "APD\n",
      "GRMN\n",
      "AEE\n",
      "HLT\n",
      "DLTR\n",
      "STE\n",
      "HAS\n",
      "TMUS\n",
      "WMT\n",
      "NTAP\n",
      "KIM\n",
      "BAX\n",
      "LMT\n",
      "ABMD\n",
      "KEY\n",
      "UNM\n",
      "KEYS\n",
      "BMY\n",
      "PSA\n",
      "WYNN\n",
      "RHI\n",
      "EFX\n",
      "NUE\n",
      "PKG\n",
      "NBL\n",
      "WAB\n",
      "CTSH\n",
      "SWK\n",
      "MU\n",
      "TRV\n",
      "L\n",
      "AEP\n",
      "CI\n",
      "DOW\n",
      "CDW\n",
      "JNJ\n",
      "WM\n",
      "DOV\n",
      "FTI\n",
      "VIAC\n",
      "CRM\n",
      "PGR\n",
      "WAT\n",
      "IEX\n",
      "BWA\n",
      "LRCX\n",
      "NWL\n",
      "UAA\n",
      "BLK\n",
      "PPL\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'505 files was adjusted'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Fix data for about 50 splits from a correction file created manually\n",
    "fix_splits('data/splits')\n",
    "\n",
    "#%%  Pull in all the dividend data\n",
    "get_divs(symbols, 'data/divs')\n",
    "\n",
    "#%%  Combine the bars (pricing data) with any splits and dividend payments\n",
    "combine_bars('data/bars', 'data/splits', 'data/divs')\n",
    "\n",
    "#%%  Create new and stock split adjusted OHLCV fields\n",
    "adj_bars('data/bars_adj')\n",
    "\n",
    "#%%\n",
    "# bars = pd.read_csv('data/bars_adj/AAPL.csv')\n",
    "# bars['close'].plot()"
   ]
  },
  {
   "source": [
    "# Financial Data API"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLYGON_FINANCIALS_URL = f\"https://api.polygon.io/v2/reference/financials/JWN?&type=Q&sort=calendarDate&apiKey={ALPACA_API_KEY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   status                                            results\n",
       "0      OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "1      OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "2      OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "3      OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "4      OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "..    ...                                                ...\n",
       "70     OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "71     OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "72     OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "73     OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "74     OK  {'ticker': 'JWN', 'period': 'Q', 'calendarDate...\n",
       "\n",
       "[75 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>OK</td>\n      <td>{'ticker': 'JWN', 'period': 'Q', 'calendarDate...</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "r = session.get(POLYGON_FINANCIALS_URL)\n",
    "\n",
    "pd.DataFrame(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ticker period calendarDate reportPeriod     updated     dateKey  \\\n",
       "0     JWN      Q   2001-06-30   2001-07-31  2020-03-20  2001-09-07   \n",
       "1     JWN      Q   2001-09-30   2001-10-31  2020-03-20  2001-12-07   \n",
       "2     JWN      Q   2001-12-31   2002-01-31  2020-03-20  2002-04-18   \n",
       "3     JWN      Q   2002-03-31   2002-04-30  2020-03-20  2002-06-07   \n",
       "4     JWN      Q   2002-06-30   2002-07-31  2020-03-20  2002-09-12   \n",
       "..    ...    ...          ...          ...         ...         ...   \n",
       "70    JWN      Q   2018-12-31   2019-02-02  2020-03-20  2019-03-18   \n",
       "71    JWN      Q   2019-03-31   2019-05-04  2020-03-20  2019-06-05   \n",
       "72    JWN      Q   2019-06-30   2019-08-03  2020-03-20  2019-09-04   \n",
       "73    JWN      Q   2019-09-30   2019-11-02  2020-03-20  2019-12-04   \n",
       "74    JWN      Q   2019-12-31   2020-02-01  2020-03-20  2020-03-20   \n",
       "\n",
       "    accumulatedOtherComprehensiveIncome       assets  assetsCurrent  \\\n",
       "0                               1118000   3792151000     1911644000   \n",
       "1                               1789000   3975151000     2021878000   \n",
       "2                                649000   4048779000     2054598000   \n",
       "3                              -3538000   4024430000     2015154000   \n",
       "4                               -714000   4231513000     2188368000   \n",
       "..                                  ...          ...            ...   \n",
       "70                            -37000000   7886000000     3374000000   \n",
       "71                            -46000000   9338000000     2958000000   \n",
       "72                            -39000000   9935000000     3483000000   \n",
       "73                            -38000000  10075000000     3573000000   \n",
       "74                            -68000000   9737000000     3230000000   \n",
       "\n",
       "    assetsNonCurrent  ...  netCashFlowFromOperations  \\\n",
       "0         1880507000  ...                        NaN   \n",
       "1         1953273000  ...                -63501000.0   \n",
       "2         1994181000  ...                253489000.0   \n",
       "3         2009276000  ...                 30591000.0   \n",
       "4         2043145000  ...                182683000.0   \n",
       "..               ...  ...                        ...   \n",
       "70        4512000000  ...                654000000.0   \n",
       "71        6380000000  ...                -31000000.0   \n",
       "72        6452000000  ...                723000000.0   \n",
       "73        6502000000  ...               -123000000.0   \n",
       "74        6507000000  ...                667000000.0   \n",
       "\n",
       "    effectOfExchangeRateChangesOnCash  shareBasedCompensation  \\\n",
       "0                                 NaN                     NaN   \n",
       "1                                 0.0               -889000.0   \n",
       "2                                 0.0               1177000.0   \n",
       "3                                 0.0               1131000.0   \n",
       "4                                 0.0                956000.0   \n",
       "..                                ...                     ...   \n",
       "70                                0.0              18000000.0   \n",
       "71                                0.0              20000000.0   \n",
       "72                                0.0              20000000.0   \n",
       "73                                0.0              15000000.0   \n",
       "74                                0.0              14000000.0   \n",
       "\n",
       "    enterpriseValueOverEBIT  enterpriseValueOverEBITDA  priceEarnings  \\\n",
       "0                       NaN                        NaN            NaN   \n",
       "1                       NaN                        NaN            NaN   \n",
       "2                      16.0                      8.936         26.828   \n",
       "3                      19.0                        NaN         43.768   \n",
       "4                      17.0                      8.604         38.740   \n",
       "..                      ...                        ...            ...   \n",
       "70                     10.0                      5.696         12.145   \n",
       "71                     12.0                      6.563          9.616   \n",
       "72                     12.0                      5.720          9.273   \n",
       "73                     12.0                      6.343         10.598   \n",
       "74                      9.0                      4.111          5.630   \n",
       "\n",
       "    priceToEarningsRatio  priceSales  priceToSalesRatio  \\\n",
       "0                    NaN         NaN                NaN   \n",
       "1                    NaN         NaN                NaN   \n",
       "2                 26.720       0.594              0.594   \n",
       "3                 42.842       0.583              0.583   \n",
       "4                 38.055       0.490              0.490   \n",
       "..                   ...         ...                ...   \n",
       "70                13.113       0.432              0.466   \n",
       "71                10.310       0.314              0.315   \n",
       "72                 9.707       0.294              0.294   \n",
       "73                10.922       0.378              0.378   \n",
       "74                 5.581       0.180              0.179   \n",
       "\n",
       "    weightedAverageSharesDiluted  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "..                           ...  \n",
       "70                   167000000.0  \n",
       "71                   156200000.0  \n",
       "72                   155600000.0  \n",
       "73                   155800000.0  \n",
       "74                   156700000.0  \n",
       "\n",
       "[75 rows x 103 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ticker</th>\n      <th>period</th>\n      <th>calendarDate</th>\n      <th>reportPeriod</th>\n      <th>updated</th>\n      <th>dateKey</th>\n      <th>accumulatedOtherComprehensiveIncome</th>\n      <th>assets</th>\n      <th>assetsCurrent</th>\n      <th>assetsNonCurrent</th>\n      <th>...</th>\n      <th>netCashFlowFromOperations</th>\n      <th>effectOfExchangeRateChangesOnCash</th>\n      <th>shareBasedCompensation</th>\n      <th>enterpriseValueOverEBIT</th>\n      <th>enterpriseValueOverEBITDA</th>\n      <th>priceEarnings</th>\n      <th>priceToEarningsRatio</th>\n      <th>priceSales</th>\n      <th>priceToSalesRatio</th>\n      <th>weightedAverageSharesDiluted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2001-06-30</td>\n      <td>2001-07-31</td>\n      <td>2020-03-20</td>\n      <td>2001-09-07</td>\n      <td>1118000</td>\n      <td>3792151000</td>\n      <td>1911644000</td>\n      <td>1880507000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2001-09-30</td>\n      <td>2001-10-31</td>\n      <td>2020-03-20</td>\n      <td>2001-12-07</td>\n      <td>1789000</td>\n      <td>3975151000</td>\n      <td>2021878000</td>\n      <td>1953273000</td>\n      <td>...</td>\n      <td>-63501000.0</td>\n      <td>0.0</td>\n      <td>-889000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2001-12-31</td>\n      <td>2002-01-31</td>\n      <td>2020-03-20</td>\n      <td>2002-04-18</td>\n      <td>649000</td>\n      <td>4048779000</td>\n      <td>2054598000</td>\n      <td>1994181000</td>\n      <td>...</td>\n      <td>253489000.0</td>\n      <td>0.0</td>\n      <td>1177000.0</td>\n      <td>16.0</td>\n      <td>8.936</td>\n      <td>26.828</td>\n      <td>26.720</td>\n      <td>0.594</td>\n      <td>0.594</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2002-03-31</td>\n      <td>2002-04-30</td>\n      <td>2020-03-20</td>\n      <td>2002-06-07</td>\n      <td>-3538000</td>\n      <td>4024430000</td>\n      <td>2015154000</td>\n      <td>2009276000</td>\n      <td>...</td>\n      <td>30591000.0</td>\n      <td>0.0</td>\n      <td>1131000.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>43.768</td>\n      <td>42.842</td>\n      <td>0.583</td>\n      <td>0.583</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2002-06-30</td>\n      <td>2002-07-31</td>\n      <td>2020-03-20</td>\n      <td>2002-09-12</td>\n      <td>-714000</td>\n      <td>4231513000</td>\n      <td>2188368000</td>\n      <td>2043145000</td>\n      <td>...</td>\n      <td>182683000.0</td>\n      <td>0.0</td>\n      <td>956000.0</td>\n      <td>17.0</td>\n      <td>8.604</td>\n      <td>38.740</td>\n      <td>38.055</td>\n      <td>0.490</td>\n      <td>0.490</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2018-12-31</td>\n      <td>2019-02-02</td>\n      <td>2020-03-20</td>\n      <td>2019-03-18</td>\n      <td>-37000000</td>\n      <td>7886000000</td>\n      <td>3374000000</td>\n      <td>4512000000</td>\n      <td>...</td>\n      <td>654000000.0</td>\n      <td>0.0</td>\n      <td>18000000.0</td>\n      <td>10.0</td>\n      <td>5.696</td>\n      <td>12.145</td>\n      <td>13.113</td>\n      <td>0.432</td>\n      <td>0.466</td>\n      <td>167000000.0</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2019-03-31</td>\n      <td>2019-05-04</td>\n      <td>2020-03-20</td>\n      <td>2019-06-05</td>\n      <td>-46000000</td>\n      <td>9338000000</td>\n      <td>2958000000</td>\n      <td>6380000000</td>\n      <td>...</td>\n      <td>-31000000.0</td>\n      <td>0.0</td>\n      <td>20000000.0</td>\n      <td>12.0</td>\n      <td>6.563</td>\n      <td>9.616</td>\n      <td>10.310</td>\n      <td>0.314</td>\n      <td>0.315</td>\n      <td>156200000.0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2019-06-30</td>\n      <td>2019-08-03</td>\n      <td>2020-03-20</td>\n      <td>2019-09-04</td>\n      <td>-39000000</td>\n      <td>9935000000</td>\n      <td>3483000000</td>\n      <td>6452000000</td>\n      <td>...</td>\n      <td>723000000.0</td>\n      <td>0.0</td>\n      <td>20000000.0</td>\n      <td>12.0</td>\n      <td>5.720</td>\n      <td>9.273</td>\n      <td>9.707</td>\n      <td>0.294</td>\n      <td>0.294</td>\n      <td>155600000.0</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2019-09-30</td>\n      <td>2019-11-02</td>\n      <td>2020-03-20</td>\n      <td>2019-12-04</td>\n      <td>-38000000</td>\n      <td>10075000000</td>\n      <td>3573000000</td>\n      <td>6502000000</td>\n      <td>...</td>\n      <td>-123000000.0</td>\n      <td>0.0</td>\n      <td>15000000.0</td>\n      <td>12.0</td>\n      <td>6.343</td>\n      <td>10.598</td>\n      <td>10.922</td>\n      <td>0.378</td>\n      <td>0.378</td>\n      <td>155800000.0</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>JWN</td>\n      <td>Q</td>\n      <td>2019-12-31</td>\n      <td>2020-02-01</td>\n      <td>2020-03-20</td>\n      <td>2020-03-20</td>\n      <td>-68000000</td>\n      <td>9737000000</td>\n      <td>3230000000</td>\n      <td>6507000000</td>\n      <td>...</td>\n      <td>667000000.0</td>\n      <td>0.0</td>\n      <td>14000000.0</td>\n      <td>9.0</td>\n      <td>4.111</td>\n      <td>5.630</td>\n      <td>5.581</td>\n      <td>0.180</td>\n      <td>0.179</td>\n      <td>156700000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 103 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "final_data = []\n",
    "\n",
    "for i in r.json()[\"results\"]:\n",
    "    x = pd.DataFrame(columns=[x[0] for x in list(i.items())],data=i, index=[0])\n",
    "    final_data.append(x)\n",
    "pd.concat(final_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5bd231e00f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;31m# GH10856\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# raise ValueError if only scalars in dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(columns=[x[0] for x in list(i.items())],data=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  ticker period calendarDate reportPeriod     updated     dateKey  \\\n",
       "0   MSFT      Q   2020-03-31   2020-03-31  2020-04-29  2020-04-29   \n",
       "\n",
       "   accumulatedOtherComprehensiveIncome        assets  assetsCurrent  \\\n",
       "0                           2676000000  285449000000   170505000000   \n",
       "\n",
       "   assetsNonCurrent  ...      shares  weightedAverageShares  \\\n",
       "0      114944000000  ...  7583440247             7602000000   \n",
       "\n",
       "   weightedAverageSharesDiluted  salesPerShare  tangibleAssetValue  taxAssets  \\\n",
       "0                    7675000000          4.607        236530000000          0   \n",
       "\n",
       "   incomeTaxExpense  taxLiabilities  tangibleAssetsBookValuePerShare  \\\n",
       "0        2091000000     32369000000                           31.114   \n",
       "\n",
       "   workingCapital  \n",
       "0    111798000000  \n",
       "\n",
       "[1 rows x 103 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ticker</th>\n      <th>period</th>\n      <th>calendarDate</th>\n      <th>reportPeriod</th>\n      <th>updated</th>\n      <th>dateKey</th>\n      <th>accumulatedOtherComprehensiveIncome</th>\n      <th>assets</th>\n      <th>assetsCurrent</th>\n      <th>assetsNonCurrent</th>\n      <th>...</th>\n      <th>shares</th>\n      <th>weightedAverageShares</th>\n      <th>weightedAverageSharesDiluted</th>\n      <th>salesPerShare</th>\n      <th>tangibleAssetValue</th>\n      <th>taxAssets</th>\n      <th>incomeTaxExpense</th>\n      <th>taxLiabilities</th>\n      <th>tangibleAssetsBookValuePerShare</th>\n      <th>workingCapital</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MSFT</td>\n      <td>Q</td>\n      <td>2020-03-31</td>\n      <td>2020-03-31</td>\n      <td>2020-04-29</td>\n      <td>2020-04-29</td>\n      <td>2676000000</td>\n      <td>285449000000</td>\n      <td>170505000000</td>\n      <td>114944000000</td>\n      <td>...</td>\n      <td>7583440247</td>\n      <td>7602000000</td>\n      <td>7675000000</td>\n      <td>4.607</td>\n      <td>236530000000</td>\n      <td>0</td>\n      <td>2091000000</td>\n      <td>32369000000</td>\n      <td>31.114</td>\n      <td>111798000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 103 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len([x[1] for x in list(i.items())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len([x[0] for x in list(i.items())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_values(['AAPL', 'QA', '2019-03-31', '2019-03-30', '2020-05-01', '2019-03-30', -1499000000, 341998000000, 123346000000, 218652000000, 22.648, -2363000000, 37988000000, 37988000000, 36194000000, 11561000000, 1.315, 2.231, 112630000000, 22429000000, 90201000000, 112630000000, 5532000000, 3040000000, 0, 0.015, 0.73, 13793000000, 16833000000, 0.29, 16833000000, 13793000000, 13793000000, 2.47, 2.46, 2.47, 105860000000, 105860000000, 965626436000, 14, 12.183, 8792000000, 1.881, 1, 21821000000, 0.376, 0, 0, 322868000000, 4884000000, 187423000000, 42104000000, 145319000000, 236138000000, 93772000000, 142366000000, 895667436000, -4954000000, -124000000, -23312000000, -2542000000, -3443000000, -29457000000, 13348000000, 15749000000, 11155000000, 0, 11561000000, 11561000000, 11561000000, 0, 0, 0.199, 8406000000, 13415000000, 30443000000, 0.296, 8.461, 15.667, 15.842, 38746000000, 0, 189.95, 3.465, 3.435, 26278000000, 64558000000, 58015000000, 58015000000, 3948000000, 1514000000, 4458000000, 1, 4715280000, 4674071000, 4700646000, 12.412, 341998000000, 0, 2232000000, 0, 73.169, 29574000000])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "i.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}